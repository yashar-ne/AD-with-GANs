{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "UeSZYnUjfx3f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679597266158,
     "user_tz": -60,
     "elapsed": 30362,
     "user": {
      "displayName": "Yashar Hassanpour",
      "userId": "15008758767005496954"
     }
    },
    "outputId": "05d2f7b3-b26f-49ca-c256-10375316b5e8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "id": "xtoXvC1nfhOK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679597269701,
     "user_tz": -60,
     "elapsed": 3551,
     "user": {
      "displayName": "Yashar Hassanpour",
      "userId": "15008758767005496954"
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, size_z, num_feature_maps, num_color_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.ConvTranspose2d(size_z, num_feature_maps * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_feature_maps*4, num_feature_maps * 2, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_feature_maps * 2, num_feature_maps, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_feature_maps, num_color_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.network(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_feature_maps, num_color_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(num_color_channels, num_feature_maps, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_feature_maps, num_feature_maps * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_feature_maps * 2, num_feature_maps * 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_feature_maps * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.network(input)\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "        \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "id": "kwb65Q9DfhOO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679597269702,
     "user_tz": -60,
     "elapsed": 17,
     "user": {
      "displayName": "Yashar Hassanpour",
      "userId": "15008758767005496954"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "learning_rate = 0.002\n",
    "num_epochs = 100\n",
    "num_color_channels = 1\n",
    "num_feature_maps_g = 32\n",
    "num_feature_maps_d = 32\n",
    "size_z = 100\n",
    "adam_beta1 = 0.2\n",
    "num_gpu = 0"
   ],
   "metadata": {
    "id": "1Y3il4ovfhOR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679597269705,
     "user_tz": -60,
     "elapsed": 18,
     "user": {
      "displayName": "Yashar Hassanpour",
      "userId": "15008758767005496954"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "generator = Generator(size_z=size_z,\n",
    "                      num_feature_maps=num_feature_maps_g,\n",
    "                      num_color_channels=num_color_channels).to(device)\n",
    "discriminator = Discriminator(num_feature_maps=num_feature_maps_d,\n",
    "                              num_color_channels=num_color_channels).to(device)"
   ],
   "metadata": {
    "id": "tCj3teR7fhOT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679597273516,
     "user_tz": -60,
     "elapsed": 3827,
     "user": {
      "displayName": "Yashar Hassanpour",
      "userId": "15008758767005496954"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(.5,), std=(.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "# Exclude 3s\n",
    "indices = \\\n",
    "          (train_dataset.targets == 1) |\\\n",
    "          (train_dataset.targets == 2) |\\\n",
    "          (train_dataset.targets == 4) |\\\n",
    "          (train_dataset.targets == 5) |\\\n",
    "          (train_dataset.targets == 6) |\\\n",
    "          (train_dataset.targets == 7) |\\\n",
    "          (train_dataset.targets == 8) |\\\n",
    "          (train_dataset.targets == 9)\n",
    "train_dataset.data, train_dataset.targets = train_dataset.data[indices], train_dataset.targets[indices]"
   ],
   "metadata": {
    "id": "VlILqAhFfhOX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679597280512,
     "user_tz": -60,
     "elapsed": 6,
     "user": {
      "displayName": "Yashar Hassanpour",
      "userId": "15008758767005496954"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the GAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, size_z, 1, 1, device=device)\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))\n",
    "\n",
    "def train_gan(save: bool):\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    iters = 0\n",
    "    dataloader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "    print(\"Starting Training Loop...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            # get batch-size from actual image batch\n",
    "            bs = real_images.shape[0]\n",
    "\n",
    "            # -- train discriminator --\n",
    "\n",
    "            # reset/clear discriminators gradient\n",
    "            discriminator.zero_grad()\n",
    "\n",
    "            # move images to either CPU or GPU\n",
    "            real_images = real_images.to(device)\n",
    "\n",
    "            # creates a label tensor filled with 1s\n",
    "            label = torch.full((bs,), real_label, device=device)\n",
    "\n",
    "            # get probs for discriminators guess on the real images\n",
    "            output = discriminator(real_images)\n",
    "\n",
    "            # get loss for real images. that means it calculates the difference\n",
    "            # between the output of the model with the current parameter and the\n",
    "            # target (goal) of what the model is supposed to do\n",
    "            # output --> current outcome of the model\n",
    "            # label  --> target of the model\n",
    "            lossD_real = criterion(output, label)\n",
    "\n",
    "            # calculates the gradient (using chain-rule)\n",
    "            # see https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
    "            lossD_real.backward()\n",
    "\n",
    "            # Gets the mean value of all results from the discriminator to get an average\n",
    "            # probability of all sample evaluations (for real data ) --> D(x)\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            # create noise as an input for the G in order to create fake images\n",
    "            noise = torch.randn(bs, size_z, 1, 1, device=device)\n",
    "\n",
    "            # use generator to map input noise to an output that is supposed do become fake images during training\n",
    "            fake_images = generator(noise)\n",
    "\n",
    "            # creates a label tensor filled with 0s\n",
    "            label.fill_(fake_label)\n",
    "\n",
    "            # get discriminators guess on fake images\n",
    "            output = discriminator(fake_images.detach())\n",
    "\n",
    "            # get loss for fake images\n",
    "            lossD_fake = criterion(output, label)\n",
    "\n",
    "            # adjust parameter to identify fakes\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            # gets the mean value of all results from the discriminator to get an average\n",
    "            # probability of all sample evaluations. this time for the fake images that were\n",
    "            # generated by the generator --> D(G(z))\n",
    "            D_G_z1 = output.mean().item()\n",
    "\n",
    "            # calculate loss\n",
    "            lossD = lossD_real + lossD_fake\n",
    "\n",
    "            # adjust models (discriminator) parameter\n",
    "            optimizerD.step()\n",
    "\n",
    "            # -- train generator --\n",
    "\n",
    "            # reset/clear generators gradient\n",
    "            generator.zero_grad()\n",
    "\n",
    "            # creates a label tensor filled with 1s\n",
    "            label.fill_(real_label)\n",
    "\n",
    "            # get discriminators guess on fake images\n",
    "            output = discriminator(fake_images)\n",
    "\n",
    "            # get loss for fake images\n",
    "            lossG = criterion(output, label)\n",
    "\n",
    "            # adjust parameter to generate fakes\n",
    "            lossG.backward()\n",
    "\n",
    "            # gets the mean value of all results from the discriminator to get an average\n",
    "            # probability of all sample evaluations. this time for the fake images that were\n",
    "            # generated by the generator --> D(G(z))\n",
    "            D_G_z2 = output.mean().item()\n",
    "\n",
    "            # adjust models (generator) parameter\n",
    "            optimizerG.step()\n",
    "            if i % 100 == 0:\n",
    "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                      % (epoch, num_epochs, i, len(dataloader),\n",
    "                         lossD.item(), lossG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "            # Save Losses for plotting later\n",
    "            G_losses.append(lossG.item())\n",
    "            D_losses.append(lossD.item())\n",
    "\n",
    "            # Check how the generator is doing by saving G's output on fixed_noise\n",
    "            if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(dataloader) - 1)):\n",
    "                with torch.no_grad():\n",
    "                    fake = generator(fixed_noise).detach().cpu()\n",
    "                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            iters += 1\n",
    "\n",
    "    if save:\n",
    "        torch.save(generator.state_dict(),'./saved_models/generator.pkl')\n",
    "        torch.save(discriminator.state_dict(),'./saved_models/discriminator.pkl')\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "    plt.plot(G_losses, label=\"G\")\n",
    "    plt.plot(D_losses, label=\"D\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.rcParams['animation.embed_limit'] = 100\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "    HTML(ani.to_jshtml())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def get_anomaly_score(x_query, g_z):\n",
    "    x_prop = discriminator(x_query)\n",
    "    g_z_prop = discriminator(g_z)\n",
    "\n",
    "    loss_residual = torch.sum(torch.abs(x_query - g_z))\n",
    "    loss_discriminative = torch.sum(torch.abs(x_prop - g_z_prop))\n",
    "\n",
    "    return (1-.1)*loss_residual + .1* loss_discriminative"
   ],
   "metadata": {
    "id": "Zomc6EGKfhOZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679597281989,
     "user_tz": -60,
     "elapsed": 42,
     "user": {
      "displayName": "Yashar Hassanpour",
      "userId": "15008758767005496954"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 1, 28, 28])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = 64\n",
    "test_size = 8\n",
    "\n",
    "test_data_mnist = test_dataset.__dict__['data'][start_idx:start_idx+test_size]\n",
    "test_data_mnist = test_data_mnist.view(test_size,1,28,28).type_as(torch.FloatTensor())\n",
    "test_data_mnist.size()\n",
    "\n"
   ],
   "metadata": {
    "id": "_hQNgN7afhOe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679597281995,
     "user_tz": -60,
     "elapsed": 38,
     "user": {
      "displayName": "Yashar Hassanpour",
      "userId": "15008758767005496954"
     }
    },
    "outputId": "a2b6a214-8f13-4bfb-8aaa-3663c4d0c936",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# %cd /content/drive/My Drive/Colab/\n",
    "# !ls\n",
    "\n",
    "def load_nns():\n",
    "    generator.load_state_dict(torch.load(\"./saved_models/generator.pkl\", map_location=torch.device(device)))\n",
    "    discriminator.load_state_dict(torch.load('./saved_models/discriminator.pkl', map_location=torch.device(device)))\n",
    "\n",
    "def run_inference():\n",
    "    z = Variable(init.normal(torch.zeros(test_size,100,1,1),mean=0.5,std=0.5),requires_grad=True)\n",
    "    # z = torch.randn(8, size_z, 1, 1, device=device)\n",
    "    z_optimizer = torch.optim.Adam([z],lr=1e-4)\n",
    "\n",
    "    gen_fake = generator(z.to(device))\n",
    "    loss = get_anomaly_score(Variable(test_data_mnist).to(device), gen_fake)\n",
    "\n",
    "    for i in range(5000):\n",
    "        gen_fake = generator(z.to(device))\n",
    "        loss = get_anomaly_score(Variable(test_data_mnist).to(device),gen_fake)\n",
    "        loss.backward()\n",
    "        z_optimizer.step()\n",
    "\n",
    "        if i%1000==0:\n",
    "            print(loss.data)\n",
    "            '''\n",
    "            target = test_data_mnist[1,0,:,:].numpy()\n",
    "            plt.imshow(target,cmap=\"gray\")\n",
    "            plt.show()\n",
    "\n",
    "            img=gen_fake.cpu().data[1,0,:,:].numpy()\n",
    "            plt.imshow(img,cmap='gray')\n",
    "            plt.show()\n",
    "            '''\n",
    "        for idx in range(test_size):\n",
    "            target = test_data_mnist[idx,0,:,:].numpy()\n",
    "            plt.imshow(target,cmap=\"gray\")\n",
    "            plt.show()\n",
    "            print(\"real data\")\n",
    "\n",
    "            img=gen_fake.cpu().data[idx,0,:,:].numpy()\n",
    "            plt.imshow(img,cmap='gray')\n",
    "            plt.show()\n",
    "            print(\"generated data\")\n",
    "            print(\"\\n------------------------------------\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_gan(save=True)"
   ],
   "metadata": {
    "id": "Qwt6o8I11h4-"
   },
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/100][0/375]\tLoss_D: 1.5781\tLoss_G: 2.3601\tD(x): 0.4827\tD(G(z)): 0.5581 / 0.1007\n",
      "[0/100][100/375]\tLoss_D: 1.2023\tLoss_G: 0.7678\tD(x): 0.4290\tD(G(z)): 0.2779 / 0.4720\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [44], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_gan(save\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn [40], line 71\u001B[0m, in \u001B[0;36mtrain_gan\u001B[0;34m(save)\u001B[0m\n\u001B[1;32m     68\u001B[0m lossD_fake \u001B[38;5;241m=\u001B[39m criterion(output, label)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# adjust parameter to identify fakes\u001B[39;00m\n\u001B[0;32m---> 71\u001B[0m \u001B[43mlossD_fake\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;66;03m# gets the mean value of all results from the discriminator to get an average\u001B[39;00m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# probability of all sample evaluations. this time for the fake images that were\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# generated by the generator --> D(G(z))\u001B[39;00m\n\u001B[1;32m     76\u001B[0m D_G_z1 \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/yasharha/AD-with-GANs/blob/adgan/src/ad-with-gan-inference.ipynb",
     "timestamp": 1679593465012
    }
   ]
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
