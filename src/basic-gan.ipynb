{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Mostly following\n",
    "- https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "- https://github.com/AKASHKADEL/dcgan-mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set device to GPU (cuda) if available"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download mnist dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.1307,), std=(0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print some datapoints using matplotlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set hyperparameter and load datasets into pytorch DataLoader. This allows to batch data and shuffle after each epoch. It also allows using multiple processors and load data directly into CUDA tensors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "learning_rate = 0.002\n",
    "num_epochs = 5\n",
    "num_color_channels = 1\n",
    "num_feature_maps_g = 32\n",
    "num_feature_maps_d = 32\n",
    "size_z = 100\n",
    "adam_beta1 = 0.2\n",
    "num_gpu = 0\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_feature_maps, num_color_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(num_color_channels, num_feature_maps, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_feature_maps, num_feature_maps * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_feature_maps * 2, num_feature_maps * 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(num_feature_maps * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.network(input)\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, size_z, num_feature_maps, num_color_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.ConvTranspose2d(size_z, num_feature_maps * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_feature_maps*4, num_feature_maps * 2, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_feature_maps * 2, num_feature_maps, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_feature_maps, num_color_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.network(input)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load Generator (CNN) class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "generator = Generator(size_z=size_z,\n",
    "                      num_feature_maps=num_feature_maps_g,\n",
    "                      num_color_channels=num_color_channels).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load Discriminator (CNN) class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "discriminator = Discriminator(num_feature_maps=num_feature_maps_d,\n",
    "                              num_color_channels=num_color_channels).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loss function and optimization functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "Epoch [1/5], step [100/128], d_loss: 0.7131, g_loss: 1.0616, D(x): 0.54, Discriminator - D(G(x)): 0.05, Generator - D(G(x)): 0.37\n",
      "Epoch [1/5], step [200/128], d_loss: 1.8929, g_loss: 4.9455, D(x): 0.98, Discriminator - D(G(x)): 0.78, Generator - D(G(x)): 0.01\n",
      "Epoch [1/5], step [300/128], d_loss: 0.5670, g_loss: 3.5370, D(x): 0.94, Discriminator - D(G(x)): 0.37, Generator - D(G(x)): 0.04\n",
      "Epoch [1/5], step [400/128], d_loss: 0.3565, g_loss: 2.9043, D(x): 0.88, Discriminator - D(G(x)): 0.19, Generator - D(G(x)): 0.07\n",
      "Epoch [2/5], step [100/128], d_loss: 0.4289, g_loss: 2.7684, D(x): 0.86, Discriminator - D(G(x)): 0.22, Generator - D(G(x)): 0.08\n",
      "Epoch [2/5], step [200/128], d_loss: 0.5336, g_loss: 2.4111, D(x): 0.79, Discriminator - D(G(x)): 0.24, Generator - D(G(x)): 0.10\n",
      "Epoch [2/5], step [300/128], d_loss: 0.6469, g_loss: 1.4077, D(x): 0.63, Discriminator - D(G(x)): 0.13, Generator - D(G(x)): 0.28\n",
      "Epoch [2/5], step [400/128], d_loss: 0.7480, g_loss: 2.0633, D(x): 0.81, Discriminator - D(G(x)): 0.38, Generator - D(G(x)): 0.15\n",
      "Epoch [3/5], step [100/128], d_loss: 0.8281, g_loss: 1.3433, D(x): 0.66, Discriminator - D(G(x)): 0.30, Generator - D(G(x)): 0.28\n",
      "Epoch [3/5], step [200/128], d_loss: 0.8348, g_loss: 2.7841, D(x): 0.89, Discriminator - D(G(x)): 0.47, Generator - D(G(x)): 0.08\n",
      "Epoch [3/5], step [300/128], d_loss: 0.8293, g_loss: 1.2568, D(x): 0.63, Discriminator - D(G(x)): 0.27, Generator - D(G(x)): 0.32\n",
      "Epoch [3/5], step [400/128], d_loss: 0.9460, g_loss: 1.6441, D(x): 0.74, Discriminator - D(G(x)): 0.43, Generator - D(G(x)): 0.22\n",
      "Epoch [4/5], step [100/128], d_loss: 0.9103, g_loss: 1.1264, D(x): 0.57, Discriminator - D(G(x)): 0.25, Generator - D(G(x)): 0.35\n",
      "Epoch [4/5], step [200/128], d_loss: 2.2063, g_loss: 0.3055, D(x): 0.16, Discriminator - D(G(x)): 0.06, Generator - D(G(x)): 0.76\n",
      "Epoch [4/5], step [300/128], d_loss: 1.2736, g_loss: 2.4241, D(x): 0.90, Discriminator - D(G(x)): 0.63, Generator - D(G(x)): 0.12\n",
      "Epoch [4/5], step [400/128], d_loss: 0.8342, g_loss: 1.2885, D(x): 0.61, Discriminator - D(G(x)): 0.24, Generator - D(G(x)): 0.31\n",
      "Epoch [5/5], step [100/128], d_loss: 0.8989, g_loss: 2.7346, D(x): 0.87, Discriminator - D(G(x)): 0.49, Generator - D(G(x)): 0.08\n",
      "Epoch [5/5], step [200/128], d_loss: 0.9100, g_loss: 1.1544, D(x): 0.59, Discriminator - D(G(x)): 0.25, Generator - D(G(x)): 0.36\n",
      "Epoch [5/5], step [300/128], d_loss: 0.9222, g_loss: 2.5713, D(x): 0.82, Discriminator - D(G(x)): 0.46, Generator - D(G(x)): 0.10\n",
      "Epoch [5/5], step [400/128], d_loss: 0.9587, g_loss: 1.8819, D(x): 0.72, Discriminator - D(G(x)): 0.41, Generator - D(G(x)): 0.18\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_images, _) in enumerate(dataloader):\n",
    "        # get batch-size from actual image batch\n",
    "        bs = real_images.shape[0]\n",
    "\n",
    "        # -- train discriminator --\n",
    "\n",
    "        # reset/clear discriminators gradient\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        # move images to either CPU or GPU\n",
    "        real_images = real_images.to(device)\n",
    "\n",
    "        # creates a label tensor filled with 1s\n",
    "        label = torch.full((bs,), real_label, device=device)\n",
    "\n",
    "        # get probs for discriminators guess on the real images\n",
    "        output = discriminator(real_images)\n",
    "\n",
    "        # get loss for real images. that means it calculates the difference\n",
    "        # between the output of the model with the current parameter and the\n",
    "        # target (goal) of what the model is supposed to do\n",
    "        # output --> current outcome of the model\n",
    "        # label  --> target of the model\n",
    "        lossD_real = criterion(output, label)\n",
    "\n",
    "        # calculates the gradient (using chain-rule)\n",
    "        # see https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
    "        lossD_real.backward()\n",
    "\n",
    "        # Gets the mean value of all results from the discriminator to get an average\n",
    "        # probability of all sample evaluations (for real data ) --> D(x)\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # create noise as an input for the G in order to create fake images\n",
    "        noise = torch.randn(bs, size_z, 1, 1, device=device)\n",
    "\n",
    "        # use generator to map input noise to an output that is supposed do become fake images during training\n",
    "        fake_images = generator(noise)\n",
    "\n",
    "        # creates a label tensor filled with 0s\n",
    "        label.fill_(fake_label)\n",
    "\n",
    "        # get discriminators guess on fake images\n",
    "        output = discriminator(fake_images.detach())\n",
    "\n",
    "        # get loss for fake images\n",
    "        lossD_fake = criterion(output, label)\n",
    "\n",
    "        # adjust parameter to identify fakes\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        # gets the mean value of all results from the discriminator to get an average\n",
    "        # probability of all sample evaluations. this time for the fake images that were\n",
    "        # generated by the generator --> D(G(z))\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        # calculate loss\n",
    "        lossD = lossD_real + lossD_fake\n",
    "\n",
    "        # adjust models (discriminator) parameter\n",
    "        optimizerD.step()\n",
    "\n",
    "        # -- train generator --\n",
    "\n",
    "        # reset/clear generators gradient\n",
    "        generator.zero_grad()\n",
    "\n",
    "        # creates a label tensor filled with 1s\n",
    "        label.fill_(real_label)\n",
    "\n",
    "        # get discriminators guess on fake images\n",
    "        output = discriminator(fake_images)\n",
    "\n",
    "        # get loss for fake images\n",
    "        lossG = criterion(output, label)\n",
    "\n",
    "        # adjust parameter to generate fakes\n",
    "        lossG.backward()\n",
    "\n",
    "        # gets the mean value of all results from the discriminator to get an average\n",
    "        # probability of all sample evaluations. this time for the fake images that were\n",
    "        # generated by the generator --> D(G(z))\n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        # adjust models (generator) parameter\n",
    "        optimizerG.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                'Epoch [{}/{}], step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, Discriminator - D(G(x)): {:.2f}, Generator - D(G(x)): {:.2f}'\n",
    "                .format(\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    i + 1,\n",
    "                    batch_size,\n",
    "                    lossD.item(),\n",
    "                    lossG.item(),\n",
    "                    D_x,\n",
    "                    D_G_z1,\n",
    "                    D_G_z2\n",
    "                )\n",
    "            )\n",
    "    generator.eval()\n",
    "    generator.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), 'model.ckpt')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
