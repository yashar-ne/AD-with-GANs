{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!cp -r /content/drive/MyDrive/Colab/data /content/data\n",
        "\n",
        "%cd /content/data\n",
        "%ls"
      ],
      "metadata": {
        "id": "9rCsmPpNzrBo",
        "outputId": "9971f6d9-d41c-4f25-df3e-2bb06ea37ec8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/data\n",
            "\u001b[0m\u001b[01;34mAnoMNIST\u001b[0m/  \u001b[01;34mlatent_space_mappings\u001b[0m/  \u001b[01;34mlatent_space_mappings_cp\u001b[0m/  \u001b[01;34mMNIST\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:49.352615778Z",
          "start_time": "2023-06-19T13:16:49.272631925Z"
        },
        "id": "uKhESdEpzmea"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, size_z, num_feature_maps, num_color_channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.size_z = size_z\n",
        "        self.network = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.size_z, num_feature_maps * 4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps * 4, num_feature_maps * 2, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps * 2, num_feature_maps, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps, num_color_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.network(x)\n",
        "        return output\n",
        "\n",
        "    def gen_shifted(self, x, shift):\n",
        "        shift = torch.unsqueeze(shift, -1)\n",
        "        shift = torch.unsqueeze(shift, -1)\n",
        "        return self.forward(x + shift)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:50.491940517Z",
          "start_time": "2023-06-19T13:16:50.476819472Z"
        },
        "id": "AZKotCEvzmee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_feature_maps, num_color_channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(num_color_channels, num_feature_maps, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps, num_feature_maps * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps * 2, num_feature_maps * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        feature = out\n",
        "        out = self.fc(out)\n",
        "        return out.view(-1, 1).squeeze(1), feature"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:51.402689357Z",
          "start_time": "2023-06-19T13:16:51.383963387Z"
        },
        "id": "9jo7Zrbczmeh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": [
        "class LatentSpaceMapper:\n",
        "\n",
        "    def __init__(self, generator: Generator, discriminator: Discriminator, device):\n",
        "        self.generator: Generator = generator\n",
        "        self.discriminator: Discriminator = discriminator\n",
        "        self.device = device\n",
        "\n",
        "    def map_image_to_point_in_latent_space(self, image: torch.Tensor, size_z=100, opt_iterations=10000):\n",
        "        z = torch.randn(1, size_z, 1, 1, device=self.device, requires_grad=True)\n",
        "        z_optimizer = torch.optim.Adam([z], lr=1e-4)\n",
        "        losses = []\n",
        "\n",
        "        for i in range(opt_iterations):\n",
        "            loss = self.__get_anomaly_score(z, image.unsqueeze(0).to(self.device))\n",
        "            loss.backward()\n",
        "            z_optimizer.step()\n",
        "            if i % 10000 == 0 or i == opt_iterations-1:\n",
        "                print(f\"Iteration: {i} -- Loss: {loss.data.item()}\")\n",
        "                losses.append(loss.data.item())\n",
        "\n",
        "        return z\n",
        "\n",
        "    def __get_anomaly_score(self, z, x_query):\n",
        "        lamda = 0.1\n",
        "        g_z = self.generator(z.to(self.device))\n",
        "        _, x_prop = self.discriminator(x_query)\n",
        "        _, g_z_prop = self.discriminator(g_z)\n",
        "\n",
        "        loss_r = torch.sum(torch.abs(x_query - g_z))\n",
        "        loss_d = torch.sum(torch.abs(x_prop - g_z_prop))\n",
        "\n",
        "        return (1 - lamda) * loss_r + lamda * loss_d"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:52.168904698Z",
          "start_time": "2023-06-19T13:16:52.152945768Z"
        },
        "id": "bDlGQeeozmej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class AnoMNIST(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        root_dir = os.path.join(root_dir, \"AnoMNIST\")\n",
        "        assert os.path.exists(os.path.join(root_dir, \"anomnist_dataset.csv\")), \"Invalid root directory\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.label = pd.read_csv(os.path.join(root_dir, \"anomnist_dataset.csv\"))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.label.iloc[idx, 0])\n",
        "        image_label = {\"label\": self.label.iloc[idx, 1], \"anomaly\": self.label.iloc[idx, 2]}\n",
        "        anomaly = self.label.iloc[idx, 2]\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, image_label\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:54.041217345Z",
          "start_time": "2023-06-19T13:16:54.019769104Z"
        },
        "id": "0Nx2n4Iizmel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMNIST(datasets.MNIST):\n",
        "  def __getitem__(self, idx):\n",
        "    return super(CustomMNIST, self).__getitem__(idx)[0], {\"label\": super(CustomMNIST, self).__getitem__(idx)[1], \"anomaly\": False}"
      ],
      "metadata": {
        "id": "YWKa60jznLPl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset = CustomMNIST(\n",
        "  root=\"./\",\n",
        "  train=True,\n",
        "  download=True,\n",
        ")\n",
        "\n",
        "# mnist_dataset[0]\n",
        "\n",
        "ano_mnist_dataset = AnoMNIST(\n",
        "  root_dir=\"./\",\n",
        ")\n",
        "\n",
        "print(mnist_dataset[0])\n",
        "print(ano_mnist_dataset[0])"
      ],
      "metadata": {
        "id": "IT0C1D6Lks-N",
        "outputId": "8a8ff6b2-2818-46f5-b44c-dc4bea6b39b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./CustomMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 133189316.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./CustomMNIST/raw/train-images-idx3-ubyte.gz to ./CustomMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./CustomMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 106446128.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./CustomMNIST/raw/train-labels-idx1-ubyte.gz to ./CustomMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./CustomMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 39264496.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./CustomMNIST/raw/t10k-images-idx3-ubyte.gz to ./CustomMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./CustomMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5433693.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./CustomMNIST/raw/t10k-labels-idx1-ubyte.gz to ./CustomMNIST/raw\n",
            "\n",
            "(<PIL.Image.Image image mode=L size=28x28 at 0x7F1A4FDCFF10>, {'label': 5, 'anomaly': False})\n",
            "(<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F198768ECE0>, {'label': 5, 'anomaly': True})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "def get_ano_mnist_dataset(transform, root_dir, labels=[], train_size=0.9):\n",
        "    ano_mnist_dataset = AnoMNIST(\n",
        "        root_dir=root_dir,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    mnist_dataset = CustomMNIST(\n",
        "        root=root_dir,\n",
        "        train=True,\n",
        "        transform=transform,\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    dat = torch.utils.data.ConcatDataset([ano_mnist_dataset, mnist_dataset])\n",
        "\n",
        "    if len(labels) > 0:\n",
        "        dat = [d for d in dat if (d[1]['label'] in labels)]\n",
        "\n",
        "    absolute_train_size = int(len(dat) * train_size)\n",
        "    absolute_test_size = len(dat) - absolute_train_size\n",
        "    return torch.utils.data.random_split(dat, [absolute_train_size, absolute_test_size])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:55.267129710Z",
          "start_time": "2023-06-19T13:16:55.250785327Z"
        },
        "id": "dvoHrYngzmeo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_color_channels = 1\n",
        "num_feature_maps_g = 64\n",
        "num_feature_maps_d = 64\n",
        "size_z = 100\n",
        "\n",
        "device"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:56.718929255Z",
          "start_time": "2023-06-19T13:16:56.701170727Z"
        },
        "id": "sy0CAfU_zmep",
        "outputId": "2274ce5c-8638-4419-c849-82d02092128b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "generator = Generator(size_z=size_z,\n",
        "                      num_feature_maps=num_feature_maps_g,\n",
        "                      num_color_channels=num_color_channels).to(device)\n",
        "discriminator = Discriminator(num_feature_maps=num_feature_maps_d,\n",
        "                              num_color_channels=num_color_channels).to(device)\n",
        "\n",
        "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab/saved_models/generator.pkl\", map_location=torch.device(device)))\n",
        "discriminator.load_state_dict(torch.load('/content/drive/MyDrive/Colab/saved_models/discriminator.pkl', map_location=torch.device(device)))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:58.039609982Z",
          "start_time": "2023-06-19T13:16:57.998343596Z"
        },
        "id": "IJj0sB2Izmeq",
        "outputId": "95704002-7f68-4ff0-ace9-405d7ce203a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(.5,), std=(.5,))\n",
        "])\n",
        "ano_mnist_dataset, ano_mnist_dataset_test = get_ano_mnist_dataset(transform=transform, root_dir=\"./\", labels=[9])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:17:07.612568050Z",
          "start_time": "2023-06-19T13:16:59.840564543Z"
        },
        "id": "BRc3Fm41zmes"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "# tpi = transforms.ToPILImage()\n",
        "# test_img = ano_mnist_dataset[2][0]\n",
        "# img = tpi(torch.squeeze(test_img))\n",
        "# img.show()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:17:08.876310989Z",
          "start_time": "2023-06-19T13:17:08.857710527Z"
        },
        "id": "iiPaI3UTzmev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "def create_cp(iteration_number):\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  shutil.make_archive(f\"/content/drive/MyDrive/Colab/data/latent_space_mappings_cp/latent_space_mappings_cp{iteration_number}\", 'zip', \"/content/data/latent_space_mappings\")"
      ],
      "metadata": {
        "id": "LSWav5lCxam9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import shutil\n",
        "\n",
        "\n",
        "%cd /content/data\n",
        "base_folder = \"/content/data/latent_space_mappings\"\n",
        "csv_path = os.path.join(base_folder, \"latent_space_mappings.csv\")\n",
        "\n",
        "if not os.path.exists(base_folder):\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "if os.path.exists(base_folder):\n",
        "    shutil.rmtree(base_folder)\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "with open(csv_path, 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    fields = [\"filename\", \"label\", \"anomaly\"]\n",
        "    writer.writerow(fields)"
      ],
      "metadata": {
        "id": "dxudG-7xvsRD",
        "outputId": "3eda8de7-f4d2-47b4-bfec-92416a97609d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5758 images left\n",
            "Iteration: 0 -- Loss: 395.83551025390625\n",
            "Iteration: 10000 -- Loss: 254.89419555664062\n",
            "Iteration: 19999 -- Loss: 181.6491241455078\n",
            "CREATING CHECKPOINT...\n",
            "Mounted at /content/drive\n",
            "5757 images left\n",
            "Iteration: 0 -- Loss: 406.3414611816406\n"
          ]
        }
      ],
      "source": [
        "lsm: LatentSpaceMapper = LatentSpaceMapper(generator=generator, discriminator=discriminator, device=device)\n",
        "mapped_images = []\n",
        "counter = len(ano_mnist_dataset)\n",
        "for img in ano_mnist_dataset:\n",
        "    if counter % 50 == 0 or counter % 5757 == 0:\n",
        "        print(\"CREATING CHECKPOINT...\")\n",
        "        create_cp(counter)\n",
        "\n",
        "    print(f\"{counter} images left\")\n",
        "\n",
        "    with open(csv_path, 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        fields = [f'mapped_z_{counter}.pt', img[1][\"label\"], img[1][\"anomaly\"]]\n",
        "        writer.writerow(fields)\n",
        "\n",
        "    mapped_z = lsm.map_image_to_point_in_latent_space(img[0], opt_iterations=20000)\n",
        "    mapped_images.append(mapped_z)\n",
        "    torch.save(mapped_z, f'./latent_space_mappings/mapped_z_{counter}.pt')\n",
        "    counter-=1\n",
        "\n",
        "create_cp(0)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:17:18.568254955Z",
          "start_time": "2023-06-19T13:17:09.250792045Z"
        },
        "id": "Y611jafizmex",
        "outputId": "0c90f710-dfb2-438b-b0f7-f5b35f2f9d25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "%cd /content/data\n",
        "base_folder = \"/content/drive/MyDrive/Colab/data/latent_space_mappings\"\n",
        "\n",
        "if os.path.exists(base_folder):\n",
        "    shutil.rmtree(base_folder)\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "!cp -r /content/data/latent_space_mappings /content/drive/MyDrive/Colab/data"
      ],
      "metadata": {
        "id": "Sam-SLrtzIEw",
        "outputId": "7e1a8d30-9601-4572-f6b2-24c19d6e636c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# img = generator(mapped_z)\n",
        "# img = tpi(torch.squeeze(img))\n",
        "# img.show()"
      ],
      "metadata": {
        "id": "B6SfUxQ_zmez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "X0h8TNjLzme0"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}