{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "9rCsmPpNzrBo",
        "outputId": "b7fe785e-5bd5-497e-cd04-75fc95034be4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:49.352615778Z",
          "start_time": "2023-06-19T13:16:49.272631925Z"
        },
        "id": "uKhESdEpzmea"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import csv\n",
        "import zipfile\n",
        "import PIL\n",
        "import math\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, size_z, num_feature_maps, num_color_channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.size_z = size_z\n",
        "        self.network = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.size_z, num_feature_maps * 4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps * 4, num_feature_maps * 2, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps * 2, num_feature_maps, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps, num_color_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.network(x)\n",
        "        return output\n",
        "\n",
        "    def gen_shifted(self, x, shift):\n",
        "        shift = torch.unsqueeze(shift, -1)\n",
        "        shift = torch.unsqueeze(shift, -1)\n",
        "        return self.forward(x + shift)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:50.491940517Z",
          "start_time": "2023-06-19T13:16:50.476819472Z"
        },
        "id": "AZKotCEvzmee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_feature_maps, num_color_channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(num_color_channels, num_feature_maps, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps, num_feature_maps * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps * 2, num_feature_maps * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        feature = out\n",
        "        out = self.fc(out)\n",
        "        return out.view(-1, 1).squeeze(1), feature"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:51.402689357Z",
          "start_time": "2023-06-19T13:16:51.383963387Z"
        },
        "id": "9jo7Zrbczmeh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "outputs": [],
      "source": [
        "class LatentSpaceMapper:\n",
        "    def __init__(self, generator: Generator, discriminator: Discriminator, device):\n",
        "        self.generator: Generator = generator\n",
        "        self.generator.to(device)\n",
        "        self.discriminator: Discriminator = discriminator\n",
        "        self.discriminator.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def map_image_to_point_in_latent_space(self, image: torch.Tensor, size_z=100, max_opt_iterations=50000, opt_threshold=140.0, plateu_threshold=0.5):\n",
        "        z = torch.randn(1, size_z, 1, 1, device=self.device, requires_grad=True)\n",
        "        z_optimizer = torch.optim.Adam([z], lr=0.8)\n",
        "        losses = []\n",
        "        final_loss = 0\n",
        "        latest_checkpoint_loss = 0\n",
        "\n",
        "        for i in range(max_opt_iterations):\n",
        "            loss = self.__get_anomaly_score(z, image.unsqueeze(0).to(self.device))\n",
        "            loss.backward()\n",
        "            z_optimizer.step()\n",
        "            final_loss = loss.data.item()\n",
        "\n",
        "            if i == 1:\n",
        "              latest_checkpoint_loss = loss.data.item()\n",
        "\n",
        "            if loss.data.item() < opt_threshold:\n",
        "                print(f\"Iteration: {i} -- Reached Defined Optimum -- Final Loss: {loss.data.item()}\")\n",
        "                break\n",
        "\n",
        "            if i % 10000 == 0 or i == max_opt_iterations-1:\n",
        "                print(f\"Iteration: {i} -- Current Loss: {loss.data.item()}\")\n",
        "                losses.append(loss.data.item())\n",
        "\n",
        "            if i % 5000 == 0:\n",
        "              if abs(loss.data.item()-latest_checkpoint_loss) < plateu_threshold:\n",
        "                print(f\"Reached Plateu at Iteration {i} -- Loss: {loss.data.item()}\")\n",
        "                break\n",
        "              latest_checkpoint_loss = loss.data.item()\n",
        "\n",
        "        return z, final_loss\n",
        "\n",
        "    def __get_anomaly_score(self, z, x_query):\n",
        "        lamda = 0.1\n",
        "        g_z = self.generator(z.to(self.device))\n",
        "        _, x_prop = self.discriminator(x_query)\n",
        "        _, g_z_prop = self.discriminator(g_z)\n",
        "\n",
        "        loss_r = torch.sum(torch.abs(x_query - g_z))\n",
        "        loss_d = torch.sum(torch.abs(x_prop - g_z_prop))\n",
        "\n",
        "        return (1 - lamda) * loss_r + lamda * loss_d"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:52.168904698Z",
          "start_time": "2023-06-19T13:16:52.152945768Z"
        },
        "id": "bDlGQeeozmej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class AnoMNIST(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        root_dir = os.path.join(root_dir, \"AnoMNIST\")\n",
        "        assert os.path.exists(os.path.join(root_dir, \"anomnist_dataset.csv\")), \"Invalid root directory\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.label = pd.read_csv(os.path.join(root_dir, \"anomnist_dataset.csv\"))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.label.iloc[idx, 0])\n",
        "        image_label = {\"label\": self.label.iloc[idx, 1], \"anomaly\": self.label.iloc[idx, 2]}\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, image_label\n",
        "\n",
        "\n",
        "class AnomalyExtendedMNIST(datasets.MNIST):\n",
        "    def __getitem__(self, idx):\n",
        "        return super(AnomalyExtendedMNIST, self).__getitem__(idx)[0], {\"label\": super(AnomalyExtendedMNIST, self).__getitem__(idx)[1], \"anomaly\": False}\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:54.041217345Z",
          "start_time": "2023-06-19T13:16:54.019769104Z"
        },
        "id": "0Nx2n4Iizmel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "source": [
        "def generate_augmented_mnist_images(base_folder, num, max_augmentation_thickness=5,\n",
        "                                    randomize_augmentation_thickness=False, labels=[]):\n",
        "    assert max_augmentation_thickness <= 7, \"max_augmentation_thickness must be smaller than 7\"\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "\n",
        "    dataset = datasets.MNIST(\n",
        "        root=base_folder,\n",
        "        train=True,\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    if len(labels) > 0:\n",
        "        dataset = [d for d in dataset if (d[1] in labels)]\n",
        "    else:\n",
        "        dataset = dataset.data\n",
        "\n",
        "    ano_mnist_drop_folder = os.path.join(base_folder, \"AnoMNIST\")\n",
        "    csv_path = os.path.join(ano_mnist_drop_folder, \"anomnist_dataset.csv\")\n",
        "\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "    os.makedirs(ano_mnist_drop_folder, exist_ok=True)\n",
        "\n",
        "    augmentation_thickness: int = random.randint(1, max_augmentation_thickness)\n",
        "    for i in range(num):\n",
        "        random_idx = random.randint(0, len(dataset) - 1)\n",
        "        img, label = dataset[random_idx]\n",
        "\n",
        "        augmentation_thickness = random.randint(3,\n",
        "                                                max_augmentation_thickness) if randomize_augmentation_thickness else augmentation_thickness\n",
        "        random_idx = random.randint(4, 20)\n",
        "        for j in range(img.size[0]):\n",
        "            for k in range(augmentation_thickness):\n",
        "                img.putpixel((j, random_idx + k + 1), 0)\n",
        "\n",
        "        img.save(os.path.join(ano_mnist_drop_folder, f\"img_aug_{label}_{i}.png\"))\n",
        "        with open(csv_path, 'a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            fields = [f'img_aug_{label}_{i}.png', f\"{label}\", \"True\"]\n",
        "            writer.writerow(fields)\n",
        "\n",
        "\n",
        "def generate_anomalous_image_files(base_folder, num, labels=[], copy_zip_to=''):\n",
        "    if os.path.exists(base_folder):\n",
        "        shutil.rmtree(base_folder)\n",
        "\n",
        "    ano_mnist_drop_folder = os.path.join(base_folder, \"AnoMNIST\")\n",
        "    csv_path = os.path.join(ano_mnist_drop_folder, \"anomnist_dataset.csv\")\n",
        "\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "    os.makedirs(ano_mnist_drop_folder, exist_ok=True)\n",
        "\n",
        "    with open(csv_path, 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        fields = [\"filename\", \"label\", \"anomaly\"]\n",
        "        writer.writerow(fields)\n",
        "\n",
        "    generate_augmented_mnist_images(base_folder, num=num, labels=labels)\n",
        "    if copy_zip_to:\n",
        "      shutil.make_archive(os.path.join(copy_zip_to, \"AnoMNIST\"), 'zip', ano_mnist_drop_folder)\n",
        "\n",
        "def get_ano_mnist_dataset(transform, root_dir, labels=[9], train_size=0.9):\n",
        "    ano_mnist_dataset = AnoMNIST(\n",
        "        root_dir=root_dir,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    mnist_dataset = AnomalyExtendedMNIST(\n",
        "        root=root_dir,\n",
        "        train=True,\n",
        "        transform=transform,\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    dat = torch.utils.data.ConcatDataset([ano_mnist_dataset, mnist_dataset])\n",
        "\n",
        "    if len(labels) > 0:\n",
        "        dat = [d for d in dat if (d[1]['label'] in labels)]\n",
        "\n",
        "    absolute_train_size = int(len(dat) * train_size)\n",
        "    absolute_test_size = len(dat) - absolute_train_size\n",
        "    return torch.utils.data.random_split(dat, [absolute_train_size, absolute_test_size])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:55.267129710Z",
          "start_time": "2023-06-19T13:16:55.250785327Z"
        },
        "id": "dvoHrYngzmeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ano_mnist_from_drive(drop_folder=base_folder):\n",
        "  with zipfile.ZipFile('/content/drive/MyDrive/Colab/data/AnoMNIST.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(base_folder)"
      ],
      "metadata": {
        "id": "CovsspsjqzjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_color_channels = 1\n",
        "num_feature_maps_g = 64\n",
        "num_feature_maps_d = 64\n",
        "size_z = 100\n",
        "\n",
        "device"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:56.718929255Z",
          "start_time": "2023-06-19T13:16:56.701170727Z"
        },
        "id": "sy0CAfU_zmep",
        "outputId": "fb2a6d19-4422-4f5f-92ec-87c33f3eb9c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "generator = Generator(size_z=size_z,\n",
        "                      num_feature_maps=num_feature_maps_g,\n",
        "                      num_color_channels=num_color_channels).to(device)\n",
        "discriminator = Discriminator(num_feature_maps=num_feature_maps_d,\n",
        "                              num_color_channels=num_color_channels).to(device)\n",
        "\n",
        "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab/saved_models/generator.pkl\", map_location=torch.device(device)))\n",
        "discriminator.load_state_dict(torch.load('/content/drive/MyDrive/Colab/saved_models/discriminator.pkl', map_location=torch.device(device)))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:58.039609982Z",
          "start_time": "2023-06-19T13:16:57.998343596Z"
        },
        "id": "IJj0sB2Izmeq",
        "outputId": "91e9d75c-6745-4cbc-8010-456386a7ecee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(.5,), std=(.5,))\n",
        "])\n",
        "\n",
        "# generate_anomalous_image_files(base_folder='/content/data', num=2000, labels=[9]) # number of normals is: 5949\n",
        "load_ano_mnist_from_drive(drop_folder='/content/data')\n",
        "ano_mnist_dataset, _ = get_ano_mnist_dataset(transform=transform, root_dir='/content/data', labels=[9])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:17:07.612568050Z",
          "start_time": "2023-06-19T13:16:59.840564543Z"
        },
        "id": "BRc3Fm41zmes"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0 -- Current Loss: 397.4893493652344\n",
            "Iteration: 3859 -- Reached Defined Optimum -- Final Loss: 139.99850463867188\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F65A5028FD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAACCUlEQVR4nO3aL4hUURTH8c8sIoLVYB4W/JMXo8HuHxSLQQRlMRotgk0xiRiMImoSy4JhXWwKgiIsKxjEYDCIGsQgK4hh7lvmzfhmbnjDKeeE4d1737vz5Tc/7jucM4OB2FgK/v4ESIAESIAESIAESIAESIAESIB4gF3Vd+6GfXgJh3AZbjW7fIHbuAu/a7cNVyABwgEGVfWBU4pdH/5/fQl/m8Ex2MLPmq3DFUiAcIBZJtwDl+AEjrbWVnFxZ3QNVykGhOc4XgMQrkACdL0NV/Aa/rSmn+EArONBa+kXvGpGb2sBwhVIgHCALhNuGfffV+VE+ohPvQKEK5AAXR5Yby6+wbvxmaoYYpmRa2ZFuAIJEA7QlRFtK4n2KpPvvek4h8+wMT57HW7OeTRcgQSYWx/YmLN+nlH+PO/GjghXIAHCAbpMeE85gz7AEaw1SyfhMG5Q0qZlY/UBcEepVs2LcAUSIBygrki1wAhXIAESIAESIAHCAerbdlXxCGeawUH4wczeSbgCCRAO0HNGtB9XNB+UBvP97ifCFUiAng+ibZUd250IVyABwgF6NuHQqM9bH+EKJEA4QM8mfKP8t+rx1NLp5uJpazpcgQTo2QPTcYHR7z+E99IDCTAZCyhUfoe9raknSmr+wmRZPVyBBFiAB1ZgsxmtwVmd2Xq4AgkQDpAdkwRIgAQIB/gHoMJAhm7t/8QAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F65A5029DB0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAADpklEQVR4nO3buatkRRQG8N+93W/Gddwd3EAUHFRMlAnERNHExEjQQAQVEZdgwMBAmHwCkUH9B0QEjRRxCQ1EZAIFhRG3QMQFBZXhOYMzvRhU3fv6bt0NPq0O6oPX3K6uqv7eqY9Tp+qcLkptjGCGed1UNN4ttiqrlzON5hrzRvN88UE9PiUygeQExt2mabepK8AmGro7D041Jmp8XjYeklsgEyj+FwZdRzay6MhSIhNITqDHEe0KivgXXrq+bSY7ok0hUNQL0XQUq7aflfPGWfu2tgaSWyATSE5gxxGVtKPx3UC95Q2oMbkFMoGeiGjgDFXjbHgKD8P1VfOn8Alegh8as5WCvHRnTG6BTCA5gaGIqHnIvxBvwN84CHstkt/C7XAdjsOrFmS381RPO5cjokwgokeEW3Au9sMjcBduJojoJ3hZvJZ6DP7EUXgeV8Md+AxOEiQ3rx5qzNkAC2QCQ/cDY3wLvxPW/3O4G1cSPNKPMKlGlPCNuLT34gT8ylA0lO8HMgFQjGj5hwLeFPe3S+Bn3EbwPX91RiD+K3fibYJI7yHujaeHCSS3QCYwHljM13EffA3PYZuggRFt11LgUngNZxE0cg18Ofzd2RFlAuiNiA7AEdHZ3E/Y9+ptr6m/PXADHoTLquZt3AjvNXoX1VeeqR6SWyATaGlgJAbDF8Q3PoBH8Qt8J0pjgn3wEGFpn63mOE0Ijc4hnOGcqoZdLAbTI/lolglE9ITlY3gCLxDdzjG8Cx/iN4JSjxNFeoUYKF0l6M9RUY3vVJNMaeXv8m6YCWB57ngf4ZDnGL6vmmeNTlsEvzhvtLBQ1rIMyS2QCfwH9QMlwcmsytjt9E6JTCA5gVZItiRT00Qx/FEJN+GLFRPl3XAzCCxzRM3lW7LqCFkVF+EjQm7vMOFWexmSWyATSE5g90RYwtN4Bi4XSyu3Oh33EHbKWT0sJTKBZcVsO6u+TlnJDN4Xb5WuxaH6CyaLHSd1bzbAAplAcgLrVVR2nVD/Lw5sC+c4B/Ek8crr8GKf5tEuuQUygeQEdvlsOBauRU1Fke4n3Iv+0T8iuQUygZ7U7b/BCA8QSuqmxCvzF8WLzFfE/F/+oVMmUGMod1xqBVLrYSrej9+Cx4lB+Fd4i6DEXNK5YQR6IqJlZb2NisgBnCSUVp6A8wkZ3VvhY21pJbdAJpCcwHoRUR2Ej/X6p24h1NpIboFMYKUGRgSaJSERtpdwvprQTovU/mttJLdAJpCcwD/j065NaQP6RQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 472.87890625\n",
            "Iteration: 10000 -- Current Loss: 229.33079528808594\n",
            "Iteration: 20000 -- Current Loss: 212.34800720214844\n",
            "Iteration: 30000 -- Current Loss: 211.41159057617188\n",
            "Reached Plateu at Iteration 30000 -- Loss: 211.41159057617188\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F65A5028940>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAB5klEQVR4nO3az6tMYRgH8M9IkZRQpCSukpSSrO5VNhbWNpas7CxsLYSVNTsLf4MNK5GdvWJD+dG1EUnRpXuxOHMmuhbvOaOezfddvefMnHc+fefpnXfecyYTtW1D8ecHEEAAAQQQQAABBBBAPWDjHNctwxp8xmO4hJ+DBipPIIDJyL9mT7C0/vQLHB00UHkCAZQDxhbhf2vlCQQQQAABBBDAwGX5FdyAe7gKz/96fbZSe4ODLSOWJxBAew2swS98o6uB1/CMP1biR/rOltZhyxMIoBzQVoQX8JWuthbhHL7A9/70O3jVv/F0K6A8gQDaauCh6dTyoz+zqe8s0f0+bYPjuAUvWwHlCQRQDmjbH9iLt3RFuBVWTPHrtyU/wJ5WQHkCAZQD2mbC26br78O6+sM/t8VXcH4QoDyBANo3KhfgPk7BRVyHR7Adx+ApTg4ClCcQQDlg7t3y/fAAh+Ajdg+6vjyBAMbeup21BbrvfxUODL6+PIEAygHzFOEZuNsf7WO6gTWolScQwNga2IwTsItuIbQ6bqDyBAIoB8zzINO12dEyPo0bqDyBAMoBI4pwB90tG3SToMvjAeUJBDB2IlrsOzvh/XhAeQIBlANGFOHZvnMHbs4JKE8ggDxRGUAAAQQQQAC/AZFCOi6NTNsEAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F65A502AE30>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAD7ElEQVR4nO3bS4tcRRTA8d/tvpNk1NaELEJAEXyQhaKCLlyIQnbu3AgiiOBCkKxFQQR30Z3gJ1A/gUTw+QVcKYIPgqhBxIXxkWjiJPbMuKi61bem3wNSs6haNPfWrb7171OHc06dOt0MoMGuFVujPzq/yweli53+o7brHsNg1Wn/r1YBigO0c5RoQcsH3wBXp7pzJU1K3nQ9m6oSHhSAdkgwFDsLRs02VMmGLTJku/rPdvGv7iO9pGSrAMUBmhvhmrlKuEEwG3/R07ZjuATb6U0Es3Qt615m44pLoAK0WLhQY4J+5O5lW2+dJ++4sjZAcQlUgOIAzT4JUth9GI7iIlFl12rFJVAB2g3C0qXweJn7aOEZvAi3EeKbi/AkfiQ6quk2HToVl0AFKA7QjAhbqzbrT54uD5QOiRHPn/gO3iAEQrfC8zgN368yNwdAAhWgOEB7tbsaEzSxgTvwM1HliAbsfrwPf+M5+JrwM0bwED4nhO25/uabyGQOi0ugArQpdYPg1m6Be3GBSDjuuk+Iju4CviIu5g624GVRR+7C+dlTZsmC8hKoAMUBmuls+SE4jl/pBdoPw7v4AF7F5e6rdruLk6LuncNTM6azd5NZXAIVYE9+YIAhIcjO91kfdRdbhETAxKs0uBnOxhu/z54uKUt1RhUgtTwY14iJ7DwBNcLHBGt0tns+0aYTeBCeEHX3p/lTJvtTveHBAJjkiBrCYl4hpqZT2xDjn0t4BK7HXqfgDJ4lqNQPcI/eqcieKen98OISqADFAZrDBJPQEoxICrQnR/8NPiFszd4URz8Nf8B9er7xprUAikugAhQHaIbd1ZDg5OZkSkfwi6iW/wiHecH3fSHYPpfxAny6KkBxCVSAdkBY+pUOO17Bl4Rk0NvwKCEI/5CwI/tsLYDiEqgAxQFmHNulkGk73WVb+nxb9wBh33iMkNs6z+KSmKwVl0AFCIYoW7GTBNOyw9waNaJ6jLqPLYIOfLsWQHEJVIDiABNDNCTwjFmtxvJxeB3uFgsJNvQC+ck7UiHltH0qLoEKEHJEm2J5bDojm7O3T21TdFanCEHQGeb6oAUVl8UlUAGKAwQl3BJRpqvh8mM94o7sON4jqu05fNM9T3u8yV16UdbqiUkFwL6q6V4iVFEdJQZgj+G3bFDuZI8IhTKT2tDkH4tLoAIs0oE8okFY0dsJZuc68Xz3TnO9XQq0UiFCfhhTXAIVoDhAu2xA5gidxjvdzVvwGqsF8XOi/eISqAD7cEZDwrHIpHR3wT8uB93HEXplB7LnJVsFKA6wVAnX+jNmeOXsrjm168UlUAGWOqP12oz1Z+HfFopLoAIUB/gPR+bRdMsVzcEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 435.19610595703125\n",
            "Iteration: 10000 -- Current Loss: 255.1029510498047\n",
            "Reached Plateu at Iteration 10000 -- Loss: 255.1029510498047\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F65A5029A80>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAABxUlEQVR4nO3ar4tUURgG4GfEYDDIBllEDGpYNxgWsdr90UQXg8kkCmIQbRtExCC4+BcYDIKgYBYEg0WwKgZZNy6yGEXFMPcKy7Jwz52Fr7xfm3Pmnnl45+Ny55yZTNTWnuLPDyCAAAIIIIAAAggggHrA3hmuPQkbsNYPLeJL0yLlCQQwGfnT7BSuw1X42w9/x7GmhcoTCKAcMOJGtAS3cAluwyp+wcfm1coTCKAc0NiE+3CaaQPehWewMB5QnkAAI25Eq0y//xewCfPjAeUJBFAOGN6EZ+GpznwBj//P3euHPzQDyhMIYHgPLMJhXIG3W+bO6x7N3zQDyhMIoBwwvAkfwk8cpNsW2F5PcBO+Dl22PIEAxu4P7FqVJxBAAAEEEEAAw56IHuAOvMTl7fNH+5Ve40QToDyBAMoBwx/JfsNz/IF3OEN3dvcZF+GVbhN9cJUnEMCwG9EBfIPlfuRcN+oH09O6kVWeQADlgGFNuIkb8AlHtkwdh0O6jcz2Kk8ggN3ZH5jHOtzHStOl5QkEUA6Y5Y9M4Bo80u2Wv2++vjyBAMoBMzfhHOzvX63t/MYdqjyBAAIIIIAAygE5tgsggAACCCCAf1sCLxSHvUeiAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F65A5029A80>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAADsUlEQVR4nO3bvYskRRgG8F/PzuzqHnqHnmIgKCoGauBHIAhiZCKCRn4hgoJgZmCukRiYHmh23IGxGoqJf4AimIj4lQgGd7Ii7t3t7e60QVXXds/0TLeLUhvUGwzVPdXVTz/18Nbbb71dTbStwgQODVuVWvWI3itsMtzl/7UCIDuAaWpNYGac/hBFWFl/ScVakWZnoAA40kANB7ihaQzZfMwNhnxUdgYKgOwAqi6CiajLGttwpTk6bBoIHmu/f8gpi66pslKy2RkoAKrliGjKyvlNNtE7qzNRJ/OmURxRATBk1b9HMINTeBy+g3Pi+nkBX8E1vSJNkXzSZnYGCoDpcJdFm8NZvAifEx7jEjyDO1InWrNedY7SYpWdgQIgO4BjiPA5eEN0RO/Dj7gfnsBep3dN0F4S4QRO4y9OAAMFQHYARyLsuqwVQfTNeAUewSfwYfPXB3Cr3tfKuhlxG1vwZzybn4ECYMERbeJOeEAMba7QWru+wMPwGd4jTu0LeBJeazp2o/GqOXNddFS1ooECIFrPargB32OXlkeaEaJtcFfTuBd2hBXRrwO327eYuszOQAGwkKjcw8/N+flyz9P4A97GTfAQfCQq5iWcp72b0rHkkdL/2RkoALIDWHBEG6L29pZ61oQF8nWCEq/Bl/CpmGQ/Lz5T992w7gzSNCacAAYKgAUNpPzisu3D13gTvhUiW8/C3XiUkC14vnPZmkRliYgKAFDNaCXJ9wznt8/C7WLEfgnOiIvoRbzFyC09TgADBUB2ANPDBkZ6ra+aM3P6JHk5/TQdPYW/4TcxrO+uhhMrawyyM1AATLcI89/dmq3FyRwqJKjhB1wlPM+MoIGj/b81NSbZGSgAsgOYLsffCCIaX6SyLz7KfVp7x9fT/2ssOwMFwDF2THpsGzfCg6Ijujr20uwMFADZAYwX4YrSyApeFRLtPtZKZq4baEt0VNkZKADGaWBF2jH99Y449bvi1A4NlrLW2RkoALIDqFK2cJNhJ9K9lpiffBnvEnZ0d8Zc1tw1PwMFQHYA0wruEUtKVohwuQguHWzBY2IQdpthEaYxUmoiqxUAYTX8ZaDXmverU/C0WFr5+9LY6bOpjabRTT1lZ6AAyA5g2tXXplga8FNzZuj9/gyhinOHkG1P8fuB9lFKVHUrprIzUAAER5Qm+kDMQ/cvPz22S4jE54S9u29ofZ+QqgWWt2+LBgoArP6+IBXijspW3iKG9ZeN+1DvyLIzUAAc4xuT/9Zy378AyA/gH6+6wSLKROOHAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 442.0037841796875\n",
            "Iteration: 10000 -- Current Loss: 199.32241821289062\n",
            "Iteration: 20000 -- Current Loss: 162.33148193359375\n"
          ]
        }
      ],
      "source": [
        "def create_cp(iteration_number):\n",
        "  print(\"CREATING CHECKPOINT...\")\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  shutil.make_archive(f\"/content/drive/MyDrive/Colab/data/latent_space_mappings_cp/latent_space_mappings_cp{iteration_number}\", 'zip', \"/content/data/latent_space_mappings\")\n",
        "\n",
        "def save_to_drive(mapped_z, iteration_number, csv_path):\n",
        "  torch.save(mapped_z, f'/content/drive/MyDrive/Colab/data/latent_space_mappings/mapped_z_{iteration_number}.pt')\n",
        "  shutil.copy(csv_path, \"/content/drive/MyDrive/Colab/data/latent_space_mappings/latent_space_mappings.csv\")\n",
        "\n",
        "base_folder = \"/content/data/latent_space_mappings\"\n",
        "csv_path = os.path.join(base_folder, \"latent_space_mappings.csv\")\n",
        "\n",
        "if not os.path.exists(base_folder):\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "if os.path.exists(base_folder):\n",
        "    shutil.rmtree(base_folder)\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "with open(csv_path, 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    fields = [\"filename\", \"label\", \"anomaly\", \"reconstruction_loss\"]\n",
        "    writer.writerow(fields)\n",
        "\n",
        "# Start mapping\n",
        "only_map_anomalies = True\n",
        "t = transforms.ToPILImage()\n",
        "lsm: LatentSpaceMapper = LatentSpaceMapper(generator=generator, discriminator=discriminator, device=device)\n",
        "mapped_images = []\n",
        "cp_counter = 0\n",
        "counter = len(ano_mnist_dataset)\n",
        "for img in ano_mnist_dataset:\n",
        "\n",
        "    # print(f\"{counter} images left\")\n",
        "\n",
        "    if (img[1][\"anomaly\"] == True and only_map_anomalies) or not only_map_anomalies:\n",
        "        mapped_z, reconstruction_loss = lsm.map_image_to_point_in_latent_space(img[0], opt_threshold=140.0)\n",
        "        mapped_images.append(mapped_z)\n",
        "        with open(csv_path, 'a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            fields = [f'mapped_z_{counter}.pt', img[1][\"label\"], img[1][\"anomaly\"], math.floor(reconstruction_loss)]\n",
        "            writer.writerow(fields)\n",
        "\n",
        "        torch.save(mapped_z, f'./latent_space_mappings/mapped_z_{counter}.pt')\n",
        "        save_to_drive(mapped_z, counter, csv_path)\n",
        "        cp_counter += 1\n",
        "        if cp_counter % 50 == 0:\n",
        "          create_cp(counter)\n",
        "          clear_output\n",
        "\n",
        "        print('Original Image')\n",
        "        t(img[0]).resize((128, 128), PIL.Image.NEAREST).show()\n",
        "        original_img = generator(mapped_z).cpu()\n",
        "        img = t(original_img[0]).resize((128, 128), PIL.Image.NEAREST)\n",
        "        print('Mapped and Reconstructed Image')\n",
        "        img.show()\n",
        "        print('-----------------------')\n",
        "\n",
        "    counter-=1\n",
        "\n",
        "create_cp(0)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:17:18.568254955Z",
          "start_time": "2023-06-19T13:17:09.250792045Z"
        },
        "id": "Y611jafizmex",
        "outputId": "1b28bea7-e629-4bdf-eec9-0cead309ca69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "%cd /content/data\n",
        "base_folder = \"/content/drive/MyDrive/Colab/data/latent_space_mappings\"\n",
        "\n",
        "if os.path.exists(base_folder):\n",
        "    shutil.rmtree(base_folder)\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "!cp -r /content/data/latent_space_mappings /content/drive/MyDrive/Colab/data"
      ],
      "metadata": {
        "id": "Sam-SLrtzIEw",
        "outputId": "7e1a8d30-9601-4572-f6b2-24c19d6e636c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# img = generator(mapped_z)\n",
        "# img = tpi(torch.squeeze(img))\n",
        "# img.show()"
      ],
      "metadata": {
        "id": "B6SfUxQ_zmez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "X0h8TNjLzme0"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}