{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import zipfile\n",
    "import PIL\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 512\n",
    "num_classes = 1\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "num_color_channels = 1\n",
    "num_feature_maps_g = 64\n",
    "num_feature_maps_d = 64\n",
    "size_z = 100\n",
    "adam_beta1 = 0.1\n",
    "test_size = 1\n",
    "\n",
    "map_anomalies = True\n",
    "map_normals = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, size_z, num_feature_maps, num_color_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.size_z = size_z\n",
    "        self.network = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.size_z, num_feature_maps * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_feature_maps * 4, num_feature_maps * 2, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_feature_maps * 2, num_feature_maps, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_feature_maps, num_color_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.network(x)\n",
    "        return output\n",
    "\n",
    "    def gen_shifted(self, x, shift):\n",
    "        shift = torch.unsqueeze(shift, -1)\n",
    "        shift = torch.unsqueeze(shift, -1)\n",
    "        return self.forward(x + shift)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_feature_maps, num_color_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(num_color_channels, num_feature_maps, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(num_feature_maps, num_feature_maps * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(num_feature_maps * 2, num_feature_maps * 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_feature_maps * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(num_feature_maps * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        feature = out\n",
    "        out = self.fc(out)\n",
    "        return out.view(-1, 1).squeeze(1), feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate and/or load Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AnoClassMNIST(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        root_dir = os.path.join(root_dir, \"AnoClassMNIST\")\n",
    "        assert os.path.exists(os.path.join(root_dir, \"ano_class_mnist_dataset.csv\")), \"Invalid root directory\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label = pd.read_csv(os.path.join(root_dir, \"ano_class_mnist_dataset.csv\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.label.iloc[idx, 0])\n",
    "        image_label = {\"label\": self.label.iloc[idx, 1], \"anomaly\": self.label.iloc[idx, 2]}\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, image_label\n",
    "\n",
    "\n",
    "class AnomalyExtendedMNIST(datasets.MNIST):\n",
    "    def __getitem__(self, idx):\n",
    "        return super(AnomalyExtendedMNIST, self).__getitem__(idx)[0], {\"label\": super(AnomalyExtendedMNIST, self).__getitem__(idx)[1], \"anomaly\": False}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_ano_class_mnist_dataset(root_dir, norm_class=9, ano_class=6, ano_fraction=0.2, copy_zip_to='/content/drive/MyDrive/Colab/data'):\n",
    "    if os.path.exists(root_dir):\n",
    "        shutil.rmtree(root_dir)\n",
    "\n",
    "    ano_mnist_drop_folder = os.path.join(root_dir, \"AnoClassMNIST\")\n",
    "    csv_path = os.path.join(ano_mnist_drop_folder, \"ano_class_mnist_dataset.csv\")\n",
    "\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    os.makedirs(ano_mnist_drop_folder, exist_ok=True)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        fields = [\"filename\", \"label\", \"anomaly\"]\n",
    "        writer.writerow(fields)\n",
    "\n",
    "    mnist_dataset = MNIST(\n",
    "        root=root_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    norms = [d for d in mnist_dataset if (d[1] == norm_class)]\n",
    "    for i, img in enumerate(norms):\n",
    "        img[0].save(os.path.join(ano_mnist_drop_folder, f\"img_{norm_class}_{i}.png\"))\n",
    "        with open(csv_path, 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            fields = [f'img_{norm_class}_{i}.png', f\"{norm_class}\", \"False\"]\n",
    "            writer.writerow(fields)\n",
    "\n",
    "\n",
    "    anos = [d for d in mnist_dataset if (d[1] == ano_class)]\n",
    "    anos = anos[:round(len(anos)*ano_fraction)]\n",
    "    for i, img in enumerate(anos):\n",
    "        img[0].save(os.path.join(ano_mnist_drop_folder, f\"img_{ano_class}_{i}.png\"))\n",
    "        with open(csv_path, 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            fields = [f'img_{ano_class}_{i}.png', f\"{ano_class}\", \"True\"]\n",
    "            writer.writerow(fields)\n",
    "\n",
    "    if copy_zip_to:\n",
    "      shutil.make_archive(os.path.join(copy_zip_to, \"AnoClassMNIST\"), 'zip', ano_mnist_drop_folder)\n",
    "\n",
    "\n",
    "def get_ano_class_mnist_dataset(root_dir, train_size=0.9, batch_size=256):\n",
    "    ano_mnist_dataset = AnoClassMNIST(\n",
    "        root_dir=root_dir,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(.5,), std=(.5,))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    return torch.utils.data.DataLoader(ano_mnist_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_ano_class_mnist_dataset('/content/data', norm_class=9, ano_class=6, ano_fraction=0.2, copy_zip_to='/content/drive/MyDrive/Colab/data')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_ano_mnist_from_drive(drop_folder):\n",
    "  with zipfile.ZipFile('/content/drive/MyDrive/Colab/data/AnoMNIST.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(drop_folder)\n",
    "\n",
    "def load_ano_class_mnist_from_drive(drop_folder):\n",
    "    if os.path.exists(drop_folder):\n",
    "        shutil.rmtree(drop_folder)\n",
    "\n",
    "    os.makedirs(drop_folder, exist_ok=True)\n",
    "    with zipfile.ZipFile('/content/drive/MyDrive/Colab/data/AnoClassMNIST.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(drop_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GAN training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator(size_z=size_z,\n",
    "                      num_feature_maps=num_feature_maps_g,\n",
    "                      num_color_channels=num_color_channels).to(device)\n",
    "discriminator = Discriminator(num_feature_maps=num_feature_maps_d,\n",
    "                              num_color_channels=num_color_channels).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "load_ano_class_mnist_from_drive(drop_folder='/content/data/AnoClassMNIST')\n",
    "ano_class_mnist_dataset = get_ano_class_mnist_dataset(root_dir='/content/data', batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch):\n",
    "    print(\"Saving Checkpoint...\")\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    timestamp = time.time()\n",
    "    torch.save(generator.state_dict(),f'/content/drive/My Drive/Colab/saved_models/generator_epoch_{epoch}_{timestamp}.pkl')\n",
    "    torch.save(discriminator.state_dict(),f'/content/drive/My Drive/Colab/saved_models/discriminator_epoch_{epoch}_{timestamp}.pkl')\n",
    "\n",
    "def save_models():\n",
    "    print(\"Saving Models...\")\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    torch.save(generator.state_dict(),f'/content/drive/My Drive/Colab/saved_models/generator_latest.pkl')\n",
    "    torch.save(discriminator.state_dict(),f'/content/drive/My Drive/Colab/saved_models/discriminator_latest.pkl')\n",
    "\n",
    "def load_models():\n",
    "    print(\"Loading Models...\")\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    generator.load_state_dict(torch.load(\"/content/drive/My Drive/Colab/saved_models/generator.pkl\", map_location=torch.device(device)))\n",
    "    discriminator.load_state_dict(torch.load('/content/drive/My Drive/Colab/saved_models/discriminator.pkl', map_location=torch.device(device)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "fixed_noise = torch.randn(64, size_z, 1, 1, device=device)\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))\n",
    "\n",
    "def train_gan(dataset):\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    iters = 0\n",
    "    #dataloader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "    #                                     batch_size=batch_size,\n",
    "    #                                     shuffle=True)\n",
    "\n",
    "    dataloader = dataset\n",
    "\n",
    "    print(\"Starting Training Loop...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            # get batch-size from actual image batch\n",
    "            bs = real_images.shape[0]\n",
    "\n",
    "            # -- train discriminator --\n",
    "\n",
    "            # reset/clear discriminators gradient\n",
    "            discriminator.zero_grad()\n",
    "\n",
    "            # move images to either CPU or GPU\n",
    "            real_images = real_images.to(device)\n",
    "\n",
    "            # creates a label tensor filled with 1s\n",
    "            label = torch.full((bs,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "            # get probs for discriminators guess on the real images\n",
    "            output, _ = discriminator(real_images)\n",
    "\n",
    "            # get loss for real images. that means it calculates the difference\n",
    "            # between the output of the model with the current parameter and the\n",
    "            # target (goal) of what the model is supposed to do\n",
    "            # output --> current outcome of the model\n",
    "            # label  --> target of the model\n",
    "            lossD_real = criterion(output, label)\n",
    "\n",
    "            # calculates the gradient (using chain-rule)\n",
    "            # see https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
    "            lossD_real.backward()\n",
    "\n",
    "            # Gets the mean value of all results from the discriminator to get an average\n",
    "            # probability of all sample evaluations (for real data ) --> D(x)\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            # create noise as an input for the G in order to create fake images\n",
    "            noise = torch.randn(bs, size_z, 1, 1, device=device)\n",
    "\n",
    "            # use generator to map input noise to an output that is supposed do become fake images during training\n",
    "            fake_images = generator(noise)\n",
    "\n",
    "            # creates a label tensor filled with 0s\n",
    "            label.fill_(fake_label)\n",
    "\n",
    "            # get discriminators guess on fake images\n",
    "            output, _ = discriminator(fake_images.detach())\n",
    "\n",
    "            # get loss for fake images\n",
    "            lossD_fake = criterion(output, label)\n",
    "\n",
    "            # adjust parameter to identify fakes\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            # gets the mean value of all results from the discriminator to get an average\n",
    "            # probability of all sample evaluations. this time for the fake images that were\n",
    "            # generated by the generator --> D(G(z))\n",
    "            D_G_z1 = output.mean().item()\n",
    "\n",
    "            # calculate loss\n",
    "            lossD = lossD_real + lossD_fake\n",
    "\n",
    "            # adjust models (discriminator) parameter\n",
    "            optimizerD.step()\n",
    "\n",
    "            # -- train generator --\n",
    "\n",
    "            # reset/clear generators gradient\n",
    "            generator.zero_grad()\n",
    "\n",
    "            # creates a label tensor filled with 1s\n",
    "            label.fill_(real_label)\n",
    "\n",
    "            # get discriminators guess on fake images\n",
    "            output, _ = discriminator(fake_images)\n",
    "            output = output.view(-1)\n",
    "\n",
    "            # get loss for fake images\n",
    "            lossG = criterion(output, label)\n",
    "\n",
    "            # adjust parameter to generate fakes\n",
    "            lossG.backward()\n",
    "\n",
    "            # gets the mean value of all results from the discriminator to get an average\n",
    "            # probability of all sample evaluations. this time for the fake images that were\n",
    "            # generated by the generator --> D(G(z))\n",
    "            D_G_z2 = output.mean().item()\n",
    "\n",
    "            # adjust models (generator) parameter\n",
    "            optimizerG.step()\n",
    "            # Save Losses for plotting later\n",
    "            G_losses.append(lossG.item())\n",
    "            D_losses.append(lossD.item())\n",
    "\n",
    "            # Check how the generator is doing by saving G's output on fixed_noise\n",
    "            if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(dataloader) - 1)):\n",
    "                with torch.no_grad():\n",
    "                    fake = generator(fixed_noise).detach().cpu()\n",
    "                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            iters += 1\n",
    "\n",
    "        print('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "              % (epoch+1, num_epochs, lossD.item(), lossG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        if epoch>0 and epoch%50 == 0:\n",
    "          save_checkpoint(epoch)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "    plt.plot(G_losses, label=\"G\")\n",
    "    plt.plot(D_losses, label=\"D\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.rcParams['animation.embed_limit'] = 100\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "    HTML(ani.to_jshtml())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_gan(ano_class_mnist_dataset)\n",
    "save_models()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Latent Space Exploration and generation of Direction-Matrix A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LatentSpaceMapper:\n",
    "    def __init__(self, generator: Generator, discriminator: Discriminator, device):\n",
    "        self.generator: Generator = generator\n",
    "        self.generator.to(device)\n",
    "        self.discriminator: Discriminator = discriminator\n",
    "        self.discriminator.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def map_image_to_point_in_latent_space(self, image: torch.Tensor, batch_size=1, size_z=100, max_opt_iterations=30000, opt_threshold=140.0, plateu_threshold=3.0, check_every_n_iter=4000, learning_rate=0.4, print_every_n_iters=10000, ignore_rules_below_threshold=50, retry_after_n_iters=10000, immediate_retry_threshold=200):\n",
    "        image.to(self.device)\n",
    "        z = torch.randn(batch_size, size_z, 1, 1, device=self.device, requires_grad=True)\n",
    "        z_optimizer = torch.optim.Adam([z], lr=learning_rate)\n",
    "        losses = []\n",
    "        final_loss = 0\n",
    "        latest_checkpoint_loss = 0\n",
    "\n",
    "        # scheduler = lr_scheduler.LinearLR(z_optimizer, start_factor=0.4, end_factor=0.001, total_iters=max_opt_iterations-(math.floor(max_opt_iterations*0.2)))\n",
    "        # scheduler = lr_scheduler.StepLR(z_optimizer, step_size=max_opt_iterations, gamma=0.9)\n",
    "        # scheduler = torch.optim.lr_scheduler.CyclicLR(z_optimizer, base_lr=0.01, max_lr=0.4, cycle_momentum=False)\n",
    "        for i in range(max_opt_iterations):\n",
    "            retry = False\n",
    "            loss = self.__get_anomaly_score(z, image.unsqueeze(0).to(self.device))\n",
    "            loss.backward()\n",
    "            z_optimizer.step()\n",
    "            final_loss = loss.data.item()\n",
    "\n",
    "            if i == 1:\n",
    "                latest_checkpoint_loss = loss.data.item()\n",
    "\n",
    "            if loss.data.item() < opt_threshold*batch_size:\n",
    "                print(f\"Iteration: {i} -- Reached Defined Optimum -- Final Loss: {loss.data.item()}\")\n",
    "                break\n",
    "\n",
    "            if (i % print_every_n_iters == 0 and i != 0) or (i == max_opt_iterations-1):\n",
    "                print(f\"Iteration: {i} -- Current Loss: {loss.data.item()} -- Current Learning-Rate: {z_optimizer.param_groups[0]['lr']}\")\n",
    "                losses.append(loss.data.item())\n",
    "\n",
    "            if i % check_every_n_iter == 0 and i != 0:\n",
    "                if abs(loss.data.item()-latest_checkpoint_loss) < plateu_threshold:\n",
    "                    print(f\"Reached Plateu at Iteration {i} -- Loss: {loss.data.item()}\")\n",
    "                    retry = True\n",
    "                    break\n",
    "                if loss.data.item() > immediate_retry_threshold:\n",
    "                    print(f\"Loss at Iteration {i} too high -- Loss: {loss.data.item()}\")\n",
    "                    retry = True\n",
    "                    break\n",
    "                latest_checkpoint_loss = loss.data.item()\n",
    "\n",
    "            if i == retry_after_n_iters and loss.data.item() > ignore_rules_below_threshold:\n",
    "                retry = True\n",
    "                break\n",
    "\n",
    "            #scheduler.step()\n",
    "\n",
    "        return z, final_loss, retry\n",
    "\n",
    "    def __get_anomaly_score(self, z, x_query):\n",
    "        lamda = 0.1\n",
    "        g_z = self.generator(z.to(self.device))\n",
    "        loss_r = torch.sum(torch.abs(x_query - g_z))\n",
    "\n",
    "        return loss_r\n",
    "\n",
    "        #_, x_prop = self.discriminator(x_query)\n",
    "        #_, g_z_prop = self.discriminator(g_z)\n",
    "        #loss_d = torch.sum(torch.abs(x_prop - g_z_prop))\n",
    "        #return (1 - lamda) * loss_r + lamda * loss_d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab/saved_models/generator.pkl\", map_location=torch.device(device)))\n",
    "discriminator.load_state_dict(torch.load('/content/drive/MyDrive/Colab/saved_models/discriminator.pkl', map_location=torch.device(device)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_cp(iteration_number):\n",
    "  print(\"CREATING CHECKPOINT...\")\n",
    "  drive.mount('/content/drive', force_remount=True)\n",
    "  shutil.make_archive(f\"/content/drive/MyDrive/Colab/data/latent_space_mappings_cp/latent_space_mappings_cp{iteration_number}\", 'zip', \"/content/data/latent_space_mappings\")\n",
    "\n",
    "def save_to_drive(mapped_z, iteration_number, csv_path):\n",
    "  torch.save(mapped_z, f'/content/drive/MyDrive/Colab/data/latent_space_mappings/mapped_z_{iteration_number}.pt')\n",
    "  shutil.copy(csv_path, \"/content/drive/MyDrive/Colab/data/latent_space_mappings/latent_space_mappings.csv\")\n",
    "\n",
    "base_folder = \"/content/data/latent_space_mappings\"\n",
    "csv_path = os.path.join(base_folder, \"latent_space_mappings.csv\")\n",
    "\n",
    "\n",
    "prepare_target_folder = True\n",
    "if prepare_target_folder:\n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(base_folder):\n",
    "        shutil.rmtree(base_folder)\n",
    "        os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        fields = [\"filename\", \"label\", \"reconstruction_loss\"]\n",
    "        writer.writerow(fields)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = transforms.ToPILImage()\n",
    "lsm: LatentSpaceMapper = LatentSpaceMapper(generator=generator, discriminator=discriminator, device=device)\n",
    "mapped_images = []\n",
    "cp_counter = 0\n",
    "counter = len(ano_class_mnist_dataset)\n",
    "\n",
    "i = 0\n",
    "retry_counter = 0\n",
    "iterator = iter(ano_class_mnist_dataset)\n",
    "d = next(iterator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "while counter > 0:\n",
    "    if i % 50 == 0 and i != 0:\n",
    "        clear_output()\n",
    "        print(\"Cleared Output...\")\n",
    "\n",
    "    print(f\"{counter} images left\")\n",
    "    print(f\"Label: {d[1]['label'].item()}\")\n",
    "\n",
    "    max_retries = 5\n",
    "    opt_threshold=60\n",
    "    ignore_rules_below_threshold=75\n",
    "    immediate_retry_threshold=110\n",
    "    max_opt_iterations=20000\n",
    "\n",
    "    if (d[1]['anomaly'].item() == True and map_anomalies) or (d[1]['anomaly'].item() == False and map_normals):\n",
    "        mapped_z, reconstruction_loss, retry = lsm.map_image_to_point_in_latent_space(d[0][0],\n",
    "                                                                            batch_size=1,\n",
    "                                                                            max_opt_iterations=max_opt_iterations,\n",
    "                                                                            plateu_threshold=0.0005,\n",
    "                                                                            check_every_n_iter=5000,\n",
    "                                                                            learning_rate=0.01,\n",
    "                                                                            print_every_n_iters=5000,\n",
    "                                                                            retry_after_n_iters=30000,\n",
    "                                                                            ignore_rules_below_threshold=ignore_rules_below_threshold,\n",
    "                                                                            opt_threshold=opt_threshold,\n",
    "                                                                            immediate_retry_threshold=immediate_retry_threshold)\n",
    "\n",
    "        if retry:\n",
    "            if retry_counter == max_retries:\n",
    "                retry_counter = 0\n",
    "                i+=1\n",
    "                counter-=1\n",
    "                print(\"Retry Limit reached. Moving on to next sample\")\n",
    "                print('Original Image That Could Not Be Mapped')\n",
    "                display(t(original_img[0]).resize((128, 128), PIL.Image.NEAREST))\n",
    "                d = next(iterator)\n",
    "                print('-----------------------')\n",
    "                continue\n",
    "            else:\n",
    "                retry_counter += 1\n",
    "                print(f\"Could not find optimal region within the defined iteration count. Retry ({retry_counter}) with another random z...\")\n",
    "                continue\n",
    "\n",
    "        retry_counter = 0\n",
    "        mapped_images.append(mapped_z)\n",
    "        with open(csv_path, 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            fields = [f'mapped_z_{counter}.pt', d[1]['label'].item(), math.floor(reconstruction_loss)]\n",
    "            writer.writerow(fields)\n",
    "\n",
    "        torch.save(mapped_z, os.path.join(base_folder, f'mapped_z_{counter}.pt'))\n",
    "        save_to_drive(mapped_z, counter, csv_path)\n",
    "        cp_counter += 1\n",
    "        if cp_counter % 50 == 0:\n",
    "            create_cp(counter)\n",
    "            clear_output\n",
    "\n",
    "        print('Original Image')\n",
    "        display(t(d[0][0]).resize((128, 128), PIL.Image.NEAREST))\n",
    "        print('Mapped and Reconstructed Image')\n",
    "        original_img = generator(mapped_z).cpu()\n",
    "        display(t(original_img[0]).resize((128, 128), PIL.Image.NEAREST))\n",
    "        print('-----------------------')\n",
    "\n",
    "    i+=1\n",
    "    counter-=1\n",
    "    d = next(iterator)\n",
    "\n",
    "create_cp(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
