{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "9rCsmPpNzrBo",
        "outputId": "1a7ac12b-c983-4019-c008-566e14ba94be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:49.352615778Z",
          "start_time": "2023-06-19T13:16:49.272631925Z"
        },
        "id": "uKhESdEpzmea"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import csv\n",
        "import zipfile\n",
        "import PIL\n",
        "import math\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, size_z, num_feature_maps, num_color_channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.size_z = size_z\n",
        "        self.network = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.size_z, num_feature_maps * 4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps * 4, num_feature_maps * 2, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps * 2, num_feature_maps, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps, num_color_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.network(x)\n",
        "        return output\n",
        "\n",
        "    def gen_shifted(self, x, shift):\n",
        "        shift = torch.unsqueeze(shift, -1)\n",
        "        shift = torch.unsqueeze(shift, -1)\n",
        "        return self.forward(x + shift)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:50.491940517Z",
          "start_time": "2023-06-19T13:16:50.476819472Z"
        },
        "id": "AZKotCEvzmee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_feature_maps, num_color_channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(num_color_channels, num_feature_maps, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps, num_feature_maps * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps * 2, num_feature_maps * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        feature = out\n",
        "        out = self.fc(out)\n",
        "        return out.view(-1, 1).squeeze(1), feature"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:51.402689357Z",
          "start_time": "2023-06-19T13:16:51.383963387Z"
        },
        "id": "9jo7Zrbczmeh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "outputs": [],
      "source": [
        "class LatentSpaceMapper:\n",
        "    def __init__(self, generator: Generator, discriminator: Discriminator, device):\n",
        "        self.generator: Generator = generator\n",
        "        self.generator.to(device)\n",
        "        self.discriminator: Discriminator = discriminator\n",
        "        self.discriminator.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def map_image_to_point_in_latent_space(self, image: torch.Tensor, batch_size=1, size_z=100, max_opt_iterations=50000, opt_threshold=140.0, plateu_threshold=3.0, plateu_check_every_n_iter=4000, learning_rate=0.4):\n",
        "        image.to(self.device)\n",
        "        z = torch.randn(batch_size, size_z, 1, 1, device=self.device, requires_grad=True)\n",
        "        z_optimizer = torch.optim.Adam([z], lr=learning_rate)\n",
        "        losses = []\n",
        "        final_loss = 0\n",
        "        latest_checkpoint_loss = 0\n",
        "\n",
        "        scheduler = lr_scheduler.LinearLR(z_optimizer, start_factor=1.0, end_factor=0.01, total_iters=max_opt_iterations-(math.floor(max_opt_iterations*0.2)))\n",
        "        for i in range(max_opt_iterations):\n",
        "            loss = self.__get_anomaly_score(z, image.unsqueeze(0).to(self.device))\n",
        "            loss.backward()\n",
        "            z_optimizer.step()\n",
        "            final_loss = loss.data.item()\n",
        "\n",
        "            if i == 1:\n",
        "              latest_checkpoint_loss = loss.data.item()\n",
        "\n",
        "            if loss.data.item() < opt_threshold*batch_size:\n",
        "                print(f\"Iteration: {i} -- Reached Defined Optimum -- Final Loss: {loss.data.item()}\")\n",
        "                break\n",
        "\n",
        "            if i % 1000 == 0 or i == max_opt_iterations-1:\n",
        "                print(f\"Iteration: {i} -- Current Loss: {loss.data.item()} -- Current Learning-Rate: {z_optimizer.param_groups[0]['lr']}\")\n",
        "                losses.append(loss.data.item())\n",
        "\n",
        "            if i % plateu_check_every_n_iter == 0:\n",
        "              if abs(loss.data.item()-latest_checkpoint_loss) < plateu_threshold:\n",
        "                print(f\"Reached Plateu at Iteration {i} -- Loss: {loss.data.item()}\")\n",
        "                break\n",
        "              latest_checkpoint_loss = loss.data.item()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "        return z, final_loss\n",
        "\n",
        "    def __get_anomaly_score(self, z, x_query):\n",
        "        lamda = 0.1\n",
        "        g_z = self.generator(z.to(self.device))\n",
        "        _, x_prop = self.discriminator(x_query)\n",
        "        _, g_z_prop = self.discriminator(g_z)\n",
        "\n",
        "        loss_r = torch.sum(torch.abs(x_query - g_z))\n",
        "        loss_d = torch.sum(torch.abs(x_prop - g_z_prop))\n",
        "\n",
        "        return (1 - lamda) * loss_r + lamda * loss_d"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:52.168904698Z",
          "start_time": "2023-06-19T13:16:52.152945768Z"
        },
        "id": "bDlGQeeozmej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class AnoMNIST(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        root_dir = os.path.join(root_dir, \"AnoMNIST\")\n",
        "        assert os.path.exists(os.path.join(root_dir, \"anomnist_dataset.csv\")), \"Invalid root directory\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.label = pd.read_csv(os.path.join(root_dir, \"anomnist_dataset.csv\"))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.label.iloc[idx, 0])\n",
        "        image_label = {\"label\": self.label.iloc[idx, 1], \"anomaly\": self.label.iloc[idx, 2]}\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, image_label\n",
        "\n",
        "\n",
        "class AnomalyExtendedMNIST(datasets.MNIST):\n",
        "    def __getitem__(self, idx):\n",
        "        return super(AnomalyExtendedMNIST, self).__getitem__(idx)[0], {\"label\": super(AnomalyExtendedMNIST, self).__getitem__(idx)[1], \"anomaly\": False}\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:54.041217345Z",
          "start_time": "2023-06-19T13:16:54.019769104Z"
        },
        "id": "0Nx2n4Iizmel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [],
      "source": [
        "def generate_augmented_mnist_images(base_folder, num, max_augmentation_thickness=5,\n",
        "                                    randomize_augmentation_thickness=False, labels=[]):\n",
        "    assert max_augmentation_thickness <= 7, \"max_augmentation_thickness must be smaller than 7\"\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "\n",
        "    dataset = datasets.MNIST(\n",
        "        root=base_folder,\n",
        "        train=True,\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    if len(labels) > 0:\n",
        "        dataset = [d for d in dataset if (d[1] in labels)]\n",
        "    else:\n",
        "        dataset = dataset.data\n",
        "\n",
        "    ano_mnist_drop_folder = os.path.join(base_folder, \"AnoMNIST\")\n",
        "    csv_path = os.path.join(ano_mnist_drop_folder, \"anomnist_dataset.csv\")\n",
        "\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "    os.makedirs(ano_mnist_drop_folder, exist_ok=True)\n",
        "\n",
        "    augmentation_thickness: int = random.randint(1, max_augmentation_thickness)\n",
        "    for i in range(num):\n",
        "        random_idx = random.randint(0, len(dataset) - 1)\n",
        "        img, label = dataset[random_idx]\n",
        "\n",
        "        augmentation_thickness = random.randint(3,\n",
        "                                                max_augmentation_thickness) if randomize_augmentation_thickness else augmentation_thickness\n",
        "        random_idx = random.randint(4, 20)\n",
        "        for j in range(img.size[0]):\n",
        "            for k in range(augmentation_thickness):\n",
        "                img.putpixel((j, random_idx + k + 1), 0)\n",
        "\n",
        "        img.save(os.path.join(ano_mnist_drop_folder, f\"img_aug_{label}_{i}.png\"))\n",
        "        with open(csv_path, 'a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            fields = [f'img_aug_{label}_{i}.png', f\"{label}\", \"True\"]\n",
        "            writer.writerow(fields)\n",
        "\n",
        "\n",
        "def generate_anomalous_image_files(base_folder, num, labels=[], copy_zip_to=''):\n",
        "    if os.path.exists(base_folder):\n",
        "        shutil.rmtree(base_folder)\n",
        "\n",
        "    ano_mnist_drop_folder = os.path.join(base_folder, \"AnoMNIST\")\n",
        "    csv_path = os.path.join(ano_mnist_drop_folder, \"anomnist_dataset.csv\")\n",
        "\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "    os.makedirs(ano_mnist_drop_folder, exist_ok=True)\n",
        "\n",
        "    with open(csv_path, 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        fields = [\"filename\", \"label\", \"anomaly\"]\n",
        "        writer.writerow(fields)\n",
        "\n",
        "    generate_augmented_mnist_images(base_folder, num=num, labels=labels)\n",
        "    if copy_zip_to:\n",
        "      shutil.make_archive(os.path.join(copy_zip_to, \"AnoMNIST\"), 'zip', ano_mnist_drop_folder)\n",
        "\n",
        "def get_ano_mnist_dataset(transform, root_dir, labels=[9], train_size=0.9):\n",
        "    ano_mnist_dataset = AnoMNIST(\n",
        "        root_dir=root_dir,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    mnist_dataset = AnomalyExtendedMNIST(\n",
        "        root=root_dir,\n",
        "        train=True,\n",
        "        transform=transform,\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    dat = torch.utils.data.ConcatDataset([ano_mnist_dataset, mnist_dataset])\n",
        "\n",
        "    if len(labels) > 0:\n",
        "        dat = [d for d in dat if (d[1]['label'] in labels)]\n",
        "\n",
        "    absolute_train_size = int(len(dat) * train_size)\n",
        "    absolute_test_size = len(dat) - absolute_train_size\n",
        "    return torch.utils.data.random_split(dat, [absolute_train_size, absolute_test_size])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:55.267129710Z",
          "start_time": "2023-06-19T13:16:55.250785327Z"
        },
        "id": "dvoHrYngzmeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ano_mnist_from_drive(drop_folder):\n",
        "  with zipfile.ZipFile('/content/drive/MyDrive/Colab/data/AnoMNIST.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(drop_folder)"
      ],
      "metadata": {
        "id": "CovsspsjqzjN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_color_channels = 1\n",
        "num_feature_maps_g = 64\n",
        "num_feature_maps_d = 64\n",
        "size_z = 100\n",
        "\n",
        "device"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:56.718929255Z",
          "start_time": "2023-06-19T13:16:56.701170727Z"
        },
        "id": "sy0CAfU_zmep",
        "outputId": "7b7b67ef-c317-498c-8600-fa835cc67a6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "generator = Generator(size_z=size_z,\n",
        "                      num_feature_maps=num_feature_maps_g,\n",
        "                      num_color_channels=num_color_channels).to(device)\n",
        "discriminator = Discriminator(num_feature_maps=num_feature_maps_d,\n",
        "                              num_color_channels=num_color_channels).to(device)\n",
        "\n",
        "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab/saved_models/generator.pkl\", map_location=torch.device(device)))\n",
        "discriminator.load_state_dict(torch.load('/content/drive/MyDrive/Colab/saved_models/discriminator.pkl', map_location=torch.device(device)))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:58.039609982Z",
          "start_time": "2023-06-19T13:16:57.998343596Z"
        },
        "id": "IJj0sB2Izmeq",
        "outputId": "6209aa4e-51dc-4677-a299-1d0c53a04e44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(.5,), std=(.5,))\n",
        "])\n",
        "\n",
        "# generate_anomalous_image_files(base_folder='/content/data', num=2000, labels=[9]) # number of normals is: 5949\n",
        "load_ano_mnist_from_drive(drop_folder='/content/data')\n",
        "ano_mnist_dataset, _ = get_ano_mnist_dataset(transform=transform, root_dir='/content/data', labels=[9])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:17:07.612568050Z",
          "start_time": "2023-06-19T13:16:59.840564543Z"
        },
        "id": "BRc3Fm41zmes"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0 -- Current Loss: 388.33062744140625 -- Current Learning-Rate: 1.0\n",
            "Iteration: 1000 -- Current Loss: 262.6026611328125 -- Current Learning-Rate: 0.9752499999999986\n",
            "Iteration: 2000 -- Current Loss: 255.47601318359375 -- Current Learning-Rate: 0.9504999999999977\n",
            "Iteration: 3000 -- Current Loss: 248.92300415039062 -- Current Learning-Rate: 0.9257499999999951\n",
            "Iteration: 4000 -- Current Loss: 246.37786865234375 -- Current Learning-Rate: 0.9009999999999914\n",
            "Iteration: 5000 -- Current Loss: 244.87286376953125 -- Current Learning-Rate: 0.8762499999999871\n",
            "Iteration: 6000 -- Current Loss: 243.72219848632812 -- Current Learning-Rate: 0.8514999999999817\n",
            "Iteration: 7000 -- Current Loss: 243.061767578125 -- Current Learning-Rate: 0.8267499999999743\n",
            "Iteration: 8000 -- Current Loss: 242.57119750976562 -- Current Learning-Rate: 0.801999999999967\n",
            "Iteration: 9000 -- Current Loss: 242.02410888671875 -- Current Learning-Rate: 0.7772499999999589\n",
            "Iteration: 10000 -- Current Loss: 241.64028930664062 -- Current Learning-Rate: 0.7524999999999488\n",
            "Iteration: 11000 -- Current Loss: 241.26150512695312 -- Current Learning-Rate: 0.727749999999939\n",
            "Iteration: 12000 -- Current Loss: 240.8110809326172 -- Current Learning-Rate: 0.7029999999999268\n",
            "Iteration: 13000 -- Current Loss: 240.33438110351562 -- Current Learning-Rate: 0.6782499999999132\n",
            "Iteration: 14000 -- Current Loss: 239.8895263671875 -- Current Learning-Rate: 0.6534999999998998\n",
            "Iteration: 15000 -- Current Loss: 239.4528045654297 -- Current Learning-Rate: 0.6287499999998853\n",
            "Iteration: 16000 -- Current Loss: 239.00868225097656 -- Current Learning-Rate: 0.6039999999998691\n",
            "Iteration: 17000 -- Current Loss: 238.58578491210938 -- Current Learning-Rate: 0.5792499999998532\n",
            "Iteration: 18000 -- Current Loss: 238.31057739257812 -- Current Learning-Rate: 0.5544999999998367\n",
            "Iteration: 19000 -- Current Loss: 238.07115173339844 -- Current Learning-Rate: 0.529749999999819\n",
            "Iteration: 20000 -- Current Loss: 237.83348083496094 -- Current Learning-Rate: 0.5049999999998014\n",
            "Iteration: 21000 -- Current Loss: 237.59658813476562 -- Current Learning-Rate: 0.4802499999998062\n",
            "Iteration: 22000 -- Current Loss: 237.38267517089844 -- Current Learning-Rate: 0.45549999999981644\n",
            "Iteration: 23000 -- Current Loss: 237.18246459960938 -- Current Learning-Rate: 0.4307499999998279\n",
            "Iteration: 24000 -- Current Loss: 236.96775817871094 -- Current Learning-Rate: 0.40599999999983777\n",
            "Iteration: 25000 -- Current Loss: 236.7731475830078 -- Current Learning-Rate: 0.3812499999998472\n",
            "Iteration: 26000 -- Current Loss: 236.62606811523438 -- Current Learning-Rate: 0.3564999999998579\n",
            "Iteration: 27000 -- Current Loss: 236.45538330078125 -- Current Learning-Rate: 0.33174999999986815\n",
            "Iteration: 28000 -- Current Loss: 236.30287170410156 -- Current Learning-Rate: 0.30699999999987815\n",
            "Iteration: 29000 -- Current Loss: 236.1865692138672 -- Current Learning-Rate: 0.28224999999988876\n",
            "Iteration: 30000 -- Current Loss: 236.12738037109375 -- Current Learning-Rate: 0.25749999999989676\n",
            "Iteration: 31000 -- Current Loss: 236.09825134277344 -- Current Learning-Rate: 0.23274999999990623\n",
            "Iteration: 32000 -- Current Loss: 236.06875610351562 -- Current Learning-Rate: 0.20799999999991617\n",
            "Iteration: 33000 -- Current Loss: 236.05453491210938 -- Current Learning-Rate: 0.1832499999999261\n",
            "Iteration: 34000 -- Current Loss: 236.01513671875 -- Current Learning-Rate: 0.15849999999993605\n",
            "Iteration: 35000 -- Current Loss: 235.97714233398438 -- Current Learning-Rate: 0.133749999999946\n",
            "Iteration: 36000 -- Current Loss: 235.92599487304688 -- Current Learning-Rate: 0.10899999999995594\n",
            "Iteration: 37000 -- Current Loss: 235.8765869140625 -- Current Learning-Rate: 0.08424999999996588\n",
            "Iteration: 38000 -- Current Loss: 235.84088134765625 -- Current Learning-Rate: 0.05949999999997582\n",
            "Iteration: 39000 -- Current Loss: 235.81341552734375 -- Current Learning-Rate: 0.034749999999985764\n",
            "Iteration: 40000 -- Current Loss: 235.80172729492188 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 41000 -- Current Loss: 235.79722595214844 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 42000 -- Current Loss: 235.79266357421875 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 43000 -- Current Loss: 235.78797912597656 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 44000 -- Current Loss: 235.7832794189453 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 45000 -- Current Loss: 235.7783966064453 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 46000 -- Current Loss: 235.77340698242188 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 47000 -- Current Loss: 235.7678985595703 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 48000 -- Current Loss: 235.76162719726562 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 49000 -- Current Loss: 235.7550811767578 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 49999 -- Current Loss: 235.74842834472656 -- Current Learning-Rate: 0.009999999999995792\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21553DC0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAABK0lEQVR4nO3aMUoDQRiG4XclYGttYxkLDyB29gExVVpBLDyGnTfwABZ2kiq3SCXiPcROo80G3Eb+kQ1f8/7VLDPDPnwMM8OyXUe29sLvFyBAgAABAgQIECBAgIA8YFIeeQBwD1wDTIFTgFv61hLgshkQT0BAHFBbhIfAHOAK+AJ4HfR/Au8Ax8BbEyCegIA4oCt9pJoDT5WB38B+EyCegIDaRjTbNjb0O84DsAA4Ggx8bgbEExAQB9SvZAA80l/JAD4A7gb9Z82AeAICGtfAzeiAeAIC4oDajWiHFU9AgAABAgQIECBAgAABAuKAxu8Df9Qa4GT7tAIuKtPiCQgQIECAAAHjnYYv8Os0LFc8AQFxwHiL8Px/0+IJCBAgQIAAAQIE+P+AAAEC4oAf3T4V+/Atc+4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21553DC0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAEAklEQVR4nO3bSYskRRQH8F92LW3bM06rg7jjwhxE1FFBPCmCgiKIF7E/gohHPYofQC9znYv4DTy5IaLoyZNeBDcQVxRc26V7urrLw4vMqqy9RyHmEA8KKjMjI//54s+LF/94Wa05bxvdOky//9RJJisAsgPotg/XcLjqfX3YM/eWirncrNLD8nugAKgaBOtwgMH/0m/raEGQyu6BAiA7gAhEHdwKf0hR5Vtswq9LOhgyQbkKetgncXtf8FtlkpHZPVAARCCqxKjZwgZ8Y8VZaVHfLE+UsnugAMgOYDQbdgne9OGvVquOFEjqAxfjdvgKfpLCDumdtvAPCzOmUeucVgCMOLAshz0B74l5yr3SZDWA13AW3jE24L2m2wNjHGpbdg8UANkBVMsQVHA5fodfpED0PLbhMrgUT8KHdcNm6XVtff1T2DVG9IoLwAMFQHYAS0m4AS9LlHkQNxK0+gFehxvwCXyG5zhCOpfdAwXAhEZUSYnOpjSqFxErtsfhbVxFDPYQnoWncB+RGq2TsqHZj2vrD9k9UABkBzBBwqHgl7104Dd4RZr7PsDXdUNwPzFJXgmnjeXnM2xaAMvugQKgO31qRgz5GG/CzbgavpSmp20iLQdXrPrcTv0nuwcKgOwAZpBwhv0tMmr34C24U1r6n4HHpJXgNVZ8p66Sll8oAJZmxW27C7fAG/i5Od2RkuUv6jNDk7smE8+V+JfdAwVAdgBVp4axxpiSNGdp1cHdcE7MkedbNtBYdg8UANkBVM0m/iaRjh0wya1WXKuIJWNbCF+mtM65lN0DBUAEokZWbAb60Li+3dYWW3f04CE8DS/iXWKmO6buZMfc0JbdAwVAdgCrpWStINLOtCq4RAjldvAAIRLsk95wgWSQ3QMFwGpLs0UJNjHGH8FNOE4I2UOWq9bZPVAAZAewGgkX2BBOCWnAFm6D71vXSURuHjeoL2X3QAEwKmSq4KTY9RhrUP9ZI8LKjPS2j+uJ+oJX4Zmphu2ODiSxMrsHCoDsAKo+UaDSJwjYrjbpMLbbti6kAZW0o7dTN3qf2NK7g5A2B0SyZFfKiqq6x32FhAVAsqpL1Mbtk5b8LdsguNXs1h3Wf0bWxQvwhMS9R/AjY5VUxwkCtwv1snugAOgewp/zG+wRZZMdYuh7pGjU2IEkW57GdVKjc+rb+iJjj0Yty+6BAiA7gBn6wAkiWvRIu3XNbNiU/e62e8FL8LCkTX2OR0nxrQlb00JDdg8UAN3pw2PE+IxU60bj6Zgc/sbOSPduE0VQh6SyppP4jnjfJuMqHCgAcOS94+b7pcamP3TqEkwbRZ0mid8zuceS3QMFwBE1oumPBKY1zDlfbA6Y+PZgJGbntAIgO4B/AeLwwb4OjfyDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 406.0272216796875 -- Current Learning-Rate: 1.0\n",
            "Iteration: 1000 -- Current Loss: 233.30557250976562 -- Current Learning-Rate: 0.9752499999999986\n",
            "Iteration: 2000 -- Current Loss: 227.41232299804688 -- Current Learning-Rate: 0.9504999999999977\n",
            "Iteration: 3000 -- Current Loss: 225.3019256591797 -- Current Learning-Rate: 0.9257499999999951\n",
            "Iteration: 4000 -- Current Loss: 224.2381591796875 -- Current Learning-Rate: 0.9009999999999914\n",
            "Iteration: 5000 -- Current Loss: 223.86866760253906 -- Current Learning-Rate: 0.8762499999999871\n",
            "Iteration: 6000 -- Current Loss: 223.57972717285156 -- Current Learning-Rate: 0.8514999999999817\n",
            "Iteration: 7000 -- Current Loss: 223.38433837890625 -- Current Learning-Rate: 0.8267499999999743\n",
            "Iteration: 8000 -- Current Loss: 223.2884521484375 -- Current Learning-Rate: 0.801999999999967\n",
            "Iteration: 9000 -- Current Loss: 223.1394805908203 -- Current Learning-Rate: 0.7772499999999589\n",
            "Iteration: 10000 -- Current Loss: 223.0293731689453 -- Current Learning-Rate: 0.7524999999999488\n",
            "Iteration: 11000 -- Current Loss: 222.9320831298828 -- Current Learning-Rate: 0.727749999999939\n",
            "Iteration: 12000 -- Current Loss: 222.87841796875 -- Current Learning-Rate: 0.7029999999999268\n",
            "Iteration: 13000 -- Current Loss: 222.8111572265625 -- Current Learning-Rate: 0.6782499999999132\n",
            "Iteration: 14000 -- Current Loss: 222.7569580078125 -- Current Learning-Rate: 0.6534999999998998\n",
            "Iteration: 15000 -- Current Loss: 222.690673828125 -- Current Learning-Rate: 0.6287499999998853\n",
            "Iteration: 16000 -- Current Loss: 222.6652374267578 -- Current Learning-Rate: 0.6039999999998691\n",
            "Iteration: 17000 -- Current Loss: 222.63429260253906 -- Current Learning-Rate: 0.5792499999998532\n",
            "Iteration: 18000 -- Current Loss: 222.6186981201172 -- Current Learning-Rate: 0.5544999999998367\n",
            "Iteration: 19000 -- Current Loss: 222.58885192871094 -- Current Learning-Rate: 0.529749999999819\n",
            "Iteration: 20000 -- Current Loss: 222.547607421875 -- Current Learning-Rate: 0.5049999999998014\n",
            "Iteration: 21000 -- Current Loss: 222.52423095703125 -- Current Learning-Rate: 0.4802499999998062\n",
            "Iteration: 22000 -- Current Loss: 222.47567749023438 -- Current Learning-Rate: 0.45549999999981644\n",
            "Iteration: 23000 -- Current Loss: 222.42584228515625 -- Current Learning-Rate: 0.4307499999998279\n",
            "Iteration: 24000 -- Current Loss: 222.37118530273438 -- Current Learning-Rate: 0.40599999999983777\n",
            "Iteration: 25000 -- Current Loss: 222.3226318359375 -- Current Learning-Rate: 0.3812499999998472\n",
            "Iteration: 26000 -- Current Loss: 222.27626037597656 -- Current Learning-Rate: 0.3564999999998579\n",
            "Iteration: 27000 -- Current Loss: 222.23672485351562 -- Current Learning-Rate: 0.33174999999986815\n",
            "Iteration: 28000 -- Current Loss: 222.20138549804688 -- Current Learning-Rate: 0.30699999999987815\n",
            "Iteration: 29000 -- Current Loss: 222.16937255859375 -- Current Learning-Rate: 0.28224999999988876\n",
            "Iteration: 30000 -- Current Loss: 222.13572692871094 -- Current Learning-Rate: 0.25749999999989676\n",
            "Iteration: 31000 -- Current Loss: 222.09317016601562 -- Current Learning-Rate: 0.23274999999990623\n",
            "Iteration: 32000 -- Current Loss: 222.059814453125 -- Current Learning-Rate: 0.20799999999991617\n",
            "Iteration: 33000 -- Current Loss: 222.04061889648438 -- Current Learning-Rate: 0.1832499999999261\n",
            "Iteration: 34000 -- Current Loss: 222.02154541015625 -- Current Learning-Rate: 0.15849999999993605\n",
            "Iteration: 35000 -- Current Loss: 222.0037078857422 -- Current Learning-Rate: 0.133749999999946\n",
            "Iteration: 36000 -- Current Loss: 221.98509216308594 -- Current Learning-Rate: 0.10899999999995594\n",
            "Iteration: 37000 -- Current Loss: 221.9659423828125 -- Current Learning-Rate: 0.08424999999996588\n",
            "Iteration: 38000 -- Current Loss: 221.9613037109375 -- Current Learning-Rate: 0.05949999999997582\n",
            "Iteration: 39000 -- Current Loss: 221.9578094482422 -- Current Learning-Rate: 0.034749999999985764\n",
            "Iteration: 40000 -- Current Loss: 221.955810546875 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 41000 -- Current Loss: 221.95498657226562 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 42000 -- Current Loss: 221.95425415039062 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 43000 -- Current Loss: 221.95359802246094 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 44000 -- Current Loss: 221.95297241210938 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 45000 -- Current Loss: 221.95242309570312 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 46000 -- Current Loss: 221.9517364501953 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 47000 -- Current Loss: 221.95115661621094 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 48000 -- Current Loss: 221.95050048828125 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 49000 -- Current Loss: 221.94985961914062 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 49999 -- Current Loss: 221.9491424560547 -- Current Learning-Rate: 0.009999999999995792\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21552350>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAABmElEQVR4nO3aoUucYRwH8M/JEAbLS2MMy8ZmujCwjIVhW7EMZM1gWdofsGBaMdmNFotpjIHdIGiazSALy0MMY4jh3hNB5O6eV/gtfJ90vHfP7z58+fHcc8/7DgZqx1zx9wcQQAABBBBAAAEEEEAAAQQQQAAe3EuVt9iC5+MrX3EA3yZMLU8ggHLAIIdUAQQQQAABVAMm7og+wUcM4fLW+3N3X/4F7+D07vrlCQRQDpjYhEuMGvCa+he+YA0+wDI2YH78oXO8gEcT6pcnEEB2xQEEEEAAAQQw/UHlEBZuXvkBf2AX7+FQt5E/nrZseQIBlAPuZ0t2hFfc2JZPPcoTCKD3HZOncIKH8BI/Z5pfnkAA5YDeC9FjONP13nDm+eUJBNB7IVoev3jTNr88gQDKAX2acBW24bvuRPJ85iLlCQRQDujThBfXBbbxu61IeQIBtPbAIj7DP0b3TvbaCpUnEEA5oLUJ1/Gabje+2Q4oTyCA1r9mK9iBZzT/EPEfJBBAOaB1IXqiezRln+6Qsm2UJxBAnh8IoBxwBRD8Je3PzzkeAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21552350>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAD0UlEQVR4nO3bz4sdRRAH8M+8N/vD7MqGbECEgIhgRAh4EQ/ePIgnjYJ4EgQRRMWDePcm/gMigieDJy9exIOCIKLgxbNIzEUQ/JEQTTRrsm88dM+86Tfv14Kh99AFC/2marq/W11UVVf1VGNorEnVCuGqHTTJkwqTdtCteAijdZe+XVQAZAdQrTLCCupWpmkHk4Fg3fIruJXwRtgkGGAFf8en+TVQAFTdRgx39X9cpR0MjS27BgqA7ADqbTiJf+Dq7VlliaPLroECoKrpZSxrp0YLqAtGa1N2DRQA2QHUY9gVHdGBWUNMA9mSsJZKL1uSXsaUXQMFQMiKOxpubXe0aubzU8FN8ei1YWFkGy35lYEKgOwAagTb2oCbA4ENAsyDAauC0/AWHoNT2CO4tfvh98FrE4Lrm7RTZ6UCIDuA6ugIKtjBe3AB7sE38CLOwaN4Ar6aP8k4/uXXQAEwTcsRa4epADNlx+fhbcHreAB+bmU2cR1+wvfw3GDGkwQb+o1joIECIDuAelVtKk3CzuBV2I8/XKFX4NrBFrzfstIgOxIz8l/bQXYNFAD12pJb8Awegh9xmZ6NnIDzeAe+xgfdArdawZEYgw6VYnUBEGl9I5zAI+3gJbM+6jN4sJ3ybvzAbDZ/qHdkrDgGGigAVmbFaQ92PmsBfy3KroECIDuA+i5C7vLvfIE0LV9CaSFzwURdWZ4SDQuASNUmnMUlQls/pSWecC0+QoBMrblRjPC4AKhOwTWxNJDs6Bz3cx4vw314GP6EJ/Ex/CHWiC6L/1xDSNmvtdOm/cHsGigAsgOo7iT4nyPdqJtK78J3uJcQVs8QLG1qhEtsO7sGCoC6JtQXhx2RBZTu4Wn4VqwIvdnnzyk/Je+Wo1kBAOrrsC0WE49+pe4cPI1nCQXyht7VyUOW9p6za6AAqDYIO7bgaLaEThDbIrv4FF7RS63G9KxqQbDLroECIDuAeo+QMp+Fi2IjI01dxmY7eiM8RezdfYF39YW6g9pOO/8Cyq6BAiA7gPpKC+MiwW9tEGxnm3Da08po9Lpt07bc6/ir5XfSW3CDmdpB9yFC+cjleACoG3r+YyRu2IHY2hgRTGNMbzP38QIxiD6Oj5J5J+L2pzWkfdEGrooFqewaKACyA1j5odNUsh3cQbik0sAn8IZ4LXj4Rjr1WPzi6UbLyq6BAqDeJHiTruOxwCA6/h68hg/hc+ZdxOw82rAsOUytslIBkB1AndamVnmkBr/Al+KNykvMlBVGgydTuqmXWk2lc1IBMOf+QNr+WmUVw4izdrMXx0ADBUB2AP8BE+LLGMoswh4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 453.46240234375 -- Current Learning-Rate: 1.0\n",
            "Iteration: 1000 -- Current Loss: 253.67630004882812 -- Current Learning-Rate: 0.9752499999999986\n",
            "Iteration: 2000 -- Current Loss: 238.08621215820312 -- Current Learning-Rate: 0.9504999999999977\n",
            "Iteration: 3000 -- Current Loss: 232.99473571777344 -- Current Learning-Rate: 0.9257499999999951\n",
            "Iteration: 4000 -- Current Loss: 231.6806640625 -- Current Learning-Rate: 0.9009999999999914\n",
            "Iteration: 5000 -- Current Loss: 229.93682861328125 -- Current Learning-Rate: 0.8762499999999871\n",
            "Iteration: 6000 -- Current Loss: 228.77566528320312 -- Current Learning-Rate: 0.8514999999999817\n",
            "Iteration: 7000 -- Current Loss: 228.18255615234375 -- Current Learning-Rate: 0.8267499999999743\n",
            "Iteration: 8000 -- Current Loss: 227.82809448242188 -- Current Learning-Rate: 0.801999999999967\n",
            "Iteration: 9000 -- Current Loss: 227.55870056152344 -- Current Learning-Rate: 0.7772499999999589\n",
            "Iteration: 10000 -- Current Loss: 227.3709716796875 -- Current Learning-Rate: 0.7524999999999488\n",
            "Iteration: 11000 -- Current Loss: 227.24459838867188 -- Current Learning-Rate: 0.727749999999939\n",
            "Iteration: 12000 -- Current Loss: 227.11962890625 -- Current Learning-Rate: 0.7029999999999268\n",
            "Iteration: 13000 -- Current Loss: 226.99856567382812 -- Current Learning-Rate: 0.6782499999999132\n",
            "Iteration: 14000 -- Current Loss: 226.8870086669922 -- Current Learning-Rate: 0.6534999999998998\n",
            "Iteration: 15000 -- Current Loss: 226.79562377929688 -- Current Learning-Rate: 0.6287499999998853\n",
            "Iteration: 16000 -- Current Loss: 226.69332885742188 -- Current Learning-Rate: 0.6039999999998691\n",
            "Iteration: 17000 -- Current Loss: 226.59164428710938 -- Current Learning-Rate: 0.5792499999998532\n",
            "Iteration: 18000 -- Current Loss: 226.49708557128906 -- Current Learning-Rate: 0.5544999999998367\n",
            "Iteration: 19000 -- Current Loss: 226.41651916503906 -- Current Learning-Rate: 0.529749999999819\n",
            "Iteration: 20000 -- Current Loss: 226.31961059570312 -- Current Learning-Rate: 0.5049999999998014\n",
            "Iteration: 21000 -- Current Loss: 226.20199584960938 -- Current Learning-Rate: 0.4802499999998062\n",
            "Iteration: 22000 -- Current Loss: 226.07443237304688 -- Current Learning-Rate: 0.45549999999981644\n",
            "Iteration: 23000 -- Current Loss: 225.93838500976562 -- Current Learning-Rate: 0.4307499999998279\n",
            "Iteration: 24000 -- Current Loss: 225.7973175048828 -- Current Learning-Rate: 0.40599999999983777\n",
            "Iteration: 25000 -- Current Loss: 225.63865661621094 -- Current Learning-Rate: 0.3812499999998472\n",
            "Iteration: 26000 -- Current Loss: 225.47145080566406 -- Current Learning-Rate: 0.3564999999998579\n",
            "Iteration: 27000 -- Current Loss: 225.3332061767578 -- Current Learning-Rate: 0.33174999999986815\n",
            "Iteration: 28000 -- Current Loss: 225.2140655517578 -- Current Learning-Rate: 0.30699999999987815\n",
            "Iteration: 29000 -- Current Loss: 225.10447692871094 -- Current Learning-Rate: 0.28224999999988876\n",
            "Iteration: 30000 -- Current Loss: 225.00497436523438 -- Current Learning-Rate: 0.25749999999989676\n",
            "Iteration: 31000 -- Current Loss: 224.92523193359375 -- Current Learning-Rate: 0.23274999999990623\n",
            "Iteration: 32000 -- Current Loss: 224.86170959472656 -- Current Learning-Rate: 0.20799999999991617\n",
            "Iteration: 33000 -- Current Loss: 224.8069305419922 -- Current Learning-Rate: 0.1832499999999261\n",
            "Iteration: 34000 -- Current Loss: 224.76513671875 -- Current Learning-Rate: 0.15849999999993605\n",
            "Iteration: 35000 -- Current Loss: 224.73219299316406 -- Current Learning-Rate: 0.133749999999946\n",
            "Iteration: 36000 -- Current Loss: 224.70654296875 -- Current Learning-Rate: 0.10899999999995594\n",
            "Iteration: 37000 -- Current Loss: 224.68675231933594 -- Current Learning-Rate: 0.08424999999996588\n",
            "Iteration: 38000 -- Current Loss: 224.67141723632812 -- Current Learning-Rate: 0.05949999999997582\n",
            "Iteration: 39000 -- Current Loss: 224.6605682373047 -- Current Learning-Rate: 0.034749999999985764\n",
            "Iteration: 40000 -- Current Loss: 224.65487670898438 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 41000 -- Current Loss: 224.65213012695312 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 42000 -- Current Loss: 224.64920043945312 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 43000 -- Current Loss: 224.64627075195312 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 44000 -- Current Loss: 224.6434783935547 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 45000 -- Current Loss: 224.64068603515625 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 46000 -- Current Loss: 224.63787841796875 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 47000 -- Current Loss: 224.635009765625 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 48000 -- Current Loss: 224.6320037841797 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 49000 -- Current Loss: 224.62860107421875 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 49999 -- Current Loss: 224.62509155273438 -- Current Learning-Rate: 0.009999999999995792\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21553280>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAABvklEQVR4nO3ZP2tTURgH4CfFpSJ1E1pUShHxIzj6FdwUN0HRoZOLFBFnEZcO7oKLbkLFyUlcVHAQQQURJ3UQnCwiwSE5xYI09yaBV+F3pnvPn+TJj5d7wrmDgdq2UPz9AQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQRQD9jXeeYmnMM2XMLDne7Lf058ASe7fmx5AgEMOr26PYFncABf4Egb2g+vsApPcQsedQWUJxBAOaDbg+gzlhhV4vnWexgOwUrrWtSj/vAPJBBAOWBiER6FJ+3uOz7BFl7CBgzb+L3egPIEApi4Gx6H18bUq8b737U2fgZuGz+MtnC6F6A8gQDKAd2K8I0xdeeJcwM/4Sas4R0cw8degPIEApi4GX2AB7gA73GH0X/v7V0Th6Zq5QkEUA6YWIS/4Gy7W/77pFPTA8oTCKD7GdFebaldXMF6r6XlCQRQDphPEV5sF297Ly1PIIBywHyKcMHUP6U8gQDmUwNDfIOvvZeWJxBAOWDmIrzO6DTzLtzvvb48gQC6vbbbo60yOh/6AQd7ry9PIIBywMxFuAnP8Zjshv8lYOYamLWVJxBAOeA3nJ8yC2+MZ8gAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21553C70>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAADlklEQVR4nO3bO4hkRRQG4O/e7t5xBkHXB4LsrGYrhr5QXFkUQQMxURHMTFwjwdxM0RURFPGBoGhiaLhopKFgoBj4RFGWxRcrqMuqM9vTBnWrunvu7Z7u2aA6qAMDt+ueqvtz5uecU6dOVbXd0oMRdlqvppVG9lDqlgpqDONDVikAsgPot4eGi84d7e+Tibs1K2CBAqDKjSD39wuA/AA6HNFyUrOfkDg9P6cUAPvgQEWIKBUz//2VBYNVdgsUANkBLEnCSpO2D80n2ciCPiq7BQqAXBlRFR+yW6AAyA5gT0dUE9xK2+30YAOuwWtwDg/B391fSosk/5TdAgVAdgCzSJhSqnY0W4MTuBG+hm0choN4ER5rTRsSeHsJgaTnWQELFACzODAn27kYbsHNcB0cxVl4HN93T6vgSvwSf+2wAhYoALIDWDItX8O7BAL+C6/Ct/HhMrzZPXUHfsMgjhRHtBoAFudADbfiGLyD1+ELQox5AS7FX3MWGZoohqejk6xSAGQHsBgJazwNx/EpPIcf4ysHm78Q6ZaS7BYoAPqp7DhPBngwKh6Dn3AtTWp8GLfBGVwBvy4KILsFCoDsAPrrhAC1TddGrAcfYhNewlPx1SPwBCFR2iKw9Qb4QEPtASH3aRN9xApYoADIDqB/jkCiI/CN3UTcJOz7PoG34/D1uJOGpPfhlbjQ3QQS9uEqQja+1Q0guwUKgJAR/Sdsr8ZF7CR3wR2ajdj9+B2e12ytXoavcLlm6CTB/9wOp2iI0i3ZLVAAZAcwPrKZkZsdgo9wdVQ6C6fxLLwflb6Ez3AP/IN1Gu6mZdtl9+wWKAD2PLbbgIc1paGjglfylib1ruE93As3aQqVKaKtE7KtiuCfBgQilUJlAYBlzo77dLUN9OEBvEFg6pMmlaqodIRA0O24UClSrQaAxQuV57uHd+AHHICLWu9Tt9NpJjjU03ik7BYoALIDuOCOyoqwNfsZnmm9P0BI+/9kIkiWJpYCIMmYhD3C2e4ZAlvGFw0qMxs41+BRfBwV1wjZ+AZN7Jtq8ExNduWSy2oAGHNgSMi0O0rnqYm3tpsHxwknticJIS/5mOldWZI0vxQqCwC0ouGMlrmBiWr6dCHh86h0iOB7tqLiQrcOslugAJiXEaXNWHAp3fId/KHpaNrU1JBOTSnNuW2Q3QIFQHYA++gt72BTu8ieJN1GmCHZLVAAXMj9guXIMEOyW6AAyA7gf3NWrrTArxrcAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 381.17352294921875 -- Current Learning-Rate: 1.0\n",
            "Iteration: 1000 -- Current Loss: 273.3819580078125 -- Current Learning-Rate: 0.9752499999999986\n",
            "Iteration: 2000 -- Current Loss: 270.853515625 -- Current Learning-Rate: 0.9504999999999977\n",
            "Iteration: 3000 -- Current Loss: 269.49627685546875 -- Current Learning-Rate: 0.9257499999999951\n",
            "Iteration: 4000 -- Current Loss: 268.2205810546875 -- Current Learning-Rate: 0.9009999999999914\n",
            "Iteration: 5000 -- Current Loss: 267.2550354003906 -- Current Learning-Rate: 0.8762499999999871\n",
            "Iteration: 6000 -- Current Loss: 266.2015380859375 -- Current Learning-Rate: 0.8514999999999817\n",
            "Iteration: 7000 -- Current Loss: 265.14630126953125 -- Current Learning-Rate: 0.8267499999999743\n",
            "Iteration: 8000 -- Current Loss: 264.213134765625 -- Current Learning-Rate: 0.801999999999967\n",
            "Iteration: 9000 -- Current Loss: 263.1225891113281 -- Current Learning-Rate: 0.7772499999999589\n",
            "Iteration: 10000 -- Current Loss: 261.978271484375 -- Current Learning-Rate: 0.7524999999999488\n",
            "Iteration: 11000 -- Current Loss: 260.81561279296875 -- Current Learning-Rate: 0.727749999999939\n",
            "Iteration: 12000 -- Current Loss: 259.4529724121094 -- Current Learning-Rate: 0.7029999999999268\n",
            "Iteration: 13000 -- Current Loss: 258.3508605957031 -- Current Learning-Rate: 0.6782499999999132\n",
            "Iteration: 14000 -- Current Loss: 257.6292724609375 -- Current Learning-Rate: 0.6534999999998998\n",
            "Iteration: 15000 -- Current Loss: 257.0110778808594 -- Current Learning-Rate: 0.6287499999998853\n",
            "Iteration: 16000 -- Current Loss: 256.4582824707031 -- Current Learning-Rate: 0.6039999999998691\n",
            "Iteration: 17000 -- Current Loss: 256.0067138671875 -- Current Learning-Rate: 0.5792499999998532\n",
            "Iteration: 18000 -- Current Loss: 255.5738983154297 -- Current Learning-Rate: 0.5544999999998367\n",
            "Iteration: 19000 -- Current Loss: 255.10525512695312 -- Current Learning-Rate: 0.529749999999819\n",
            "Iteration: 20000 -- Current Loss: 254.6976776123047 -- Current Learning-Rate: 0.5049999999998014\n",
            "Iteration: 21000 -- Current Loss: 254.3109893798828 -- Current Learning-Rate: 0.4802499999998062\n",
            "Iteration: 22000 -- Current Loss: 253.9415740966797 -- Current Learning-Rate: 0.45549999999981644\n",
            "Iteration: 23000 -- Current Loss: 253.62254333496094 -- Current Learning-Rate: 0.4307499999998279\n",
            "Iteration: 24000 -- Current Loss: 253.33633422851562 -- Current Learning-Rate: 0.40599999999983777\n",
            "Iteration: 25000 -- Current Loss: 253.05535888671875 -- Current Learning-Rate: 0.3812499999998472\n",
            "Iteration: 26000 -- Current Loss: 252.77413940429688 -- Current Learning-Rate: 0.3564999999998579\n",
            "Iteration: 27000 -- Current Loss: 252.49728393554688 -- Current Learning-Rate: 0.33174999999986815\n",
            "Iteration: 28000 -- Current Loss: 252.2445526123047 -- Current Learning-Rate: 0.30699999999987815\n",
            "Iteration: 29000 -- Current Loss: 252.00143432617188 -- Current Learning-Rate: 0.28224999999988876\n",
            "Iteration: 30000 -- Current Loss: 251.77731323242188 -- Current Learning-Rate: 0.25749999999989676\n",
            "Iteration: 31000 -- Current Loss: 251.52047729492188 -- Current Learning-Rate: 0.23274999999990623\n",
            "Iteration: 32000 -- Current Loss: 251.26170349121094 -- Current Learning-Rate: 0.20799999999991617\n",
            "Iteration: 33000 -- Current Loss: 251.0066375732422 -- Current Learning-Rate: 0.1832499999999261\n",
            "Iteration: 34000 -- Current Loss: 250.75218200683594 -- Current Learning-Rate: 0.15849999999993605\n",
            "Iteration: 35000 -- Current Loss: 250.5575714111328 -- Current Learning-Rate: 0.133749999999946\n",
            "Iteration: 36000 -- Current Loss: 250.3965606689453 -- Current Learning-Rate: 0.10899999999995594\n",
            "Iteration: 37000 -- Current Loss: 250.27157592773438 -- Current Learning-Rate: 0.08424999999996588\n",
            "Iteration: 38000 -- Current Loss: 250.1741485595703 -- Current Learning-Rate: 0.05949999999997582\n",
            "Iteration: 39000 -- Current Loss: 250.1065673828125 -- Current Learning-Rate: 0.034749999999985764\n",
            "Iteration: 40000 -- Current Loss: 250.07473754882812 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 41000 -- Current Loss: 250.06072998046875 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 42000 -- Current Loss: 250.0458984375 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 43000 -- Current Loss: 250.02999877929688 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 44000 -- Current Loss: 250.01284790039062 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 45000 -- Current Loss: 249.99429321289062 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 46000 -- Current Loss: 249.9744110107422 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 47000 -- Current Loss: 249.95318603515625 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 48000 -- Current Loss: 249.93060302734375 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 49000 -- Current Loss: 249.90792846679688 -- Current Learning-Rate: 0.009999999999995792\n",
            "Iteration: 49999 -- Current Loss: 249.88485717773438 -- Current Learning-Rate: 0.009999999999995792\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21553A30>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAByklEQVR4nO3aP2sUQRgH4OdEgnbBQtBCJFgEC0ErQVSIhaD5AloE0VLsJNgJ2oiVhYqdwT8gFhZWloIgWOgHELS2DBaS0uL2lJDjnDHIa/F7q92b2bmH3w23czs3GqmtHcXvH0AAAQQQQAABBBBAAAEEUA/Y2X/JEnzGSzgO9/AWruEjvMb7ltHKEwigHNA5CW/jDHzCUXgHV4ZXfMAqnMSJlhHLEwigHNA+CQ/DeSzAM+ze1H4OLk3OTrcOW55AAO1zYD8cxAN4uKX9GOydnD3FhZZhyxMIoBwwanpafgRP4BS+T++zB75hHVbwpmXo8gQCaPsiWjLcjC7i0fQ+LyYHazR+/vwHCQRQDmibhAvYgB/T2+eHPhhugqutgPIEAmibA4dwg+GOtLVu4gDjxfL1LkB5AgGUA9qX5Wsz2uYmB2dxuQtQnkAA5YC2Zfk/rPIEAggggAACKAd07pjM4znjrZE7jJ8YuIv7cKsbUJ5AAOWAzkm4brxr8rs2YJfZy/YZVZ5AAFkVBxBAAAEEEMBf/Jtucy3DKyzC1+7ryxMIoByw7Un4q+b+3GValScQwLaX5Y9hH77A1e7ryxMIoByQ34YBBBBAOeAng/Yr8U0uPPAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21553A30>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAADnElEQVR4nO3bvatcRRgG8N/Zu7v3+hUCRiTGEFG0MZWFX40gaGslYqu1jSKIhZU2CqLkT7CxsLWKlQiKYCUG/AAlRPFbxKjxJrvHYmbOntnd6929NzhbzFMs58yZmfPsOw/vvPvOu83AimigxSBdbME03bVrT0SarSQqgeIEmkMwGBAlNTnkJCVRCRxGA1cFpd9fCZQnMOyumqx95b3tsChugUpgpoH/bdVzFLdAJVCcwHC/Di3zTipDHmRnzUtk3eDadHOFDbBAJbCvBhBWs9PBDvyJS1LzDzgFZ3AdvIov09DZsFswEp9N2QALVALFCQy34TJOwvnU3mkn90F34S34FffAGL7DbbCN+8RO92dD/0kdLxO+eBVhJQCGuwR/+C1Bcg2B2ISoFGJK6qjo8j7HBXpq/RkewU1EJWbottUb4bfUXNwClcCwJcYmCScIqrhATwMPEvzLc/C2fsTT4F6CozkOFy0NlnbxU9Zc3AKVQHECISTLlPI9YZObZj1fJ8RVY/1n26l5ShDwL3BaUOQcpvMvK2+BSmAuLB+kpol5DZyFR/EuvYVs4Qkcg1vxBnxgPoXdEHa0K+muTW8sikqgOIE5EZ7EEfhM32OMcDu8gx9T6xYxGn8R1xN0+xX8sfCmAT1d1t1wcwgM86sj4jrlO8ZEzAacFT3KGC8TY+ChqIFLQrA0Qxdjd2e8OYpboBIoTmDYfd5BkMw3i71aPA3n8BIh9Hmqm+AFPAPPCxH5DN357h7Z+OIWqASKEwginIh720gMmXLJtLgTrhGyocaik3sNPhT94t1iyJYNDXMvR3ELVAKr1w80cDMeIPwYe5+QsfQmniSkhs6lETvE3PhF1RFVAnvi0EUsI/hEzLY/jvfWGl/cApXAasd2GZYc5u7gC/h07dmKW6ASKE5gTRFmuamGmKg8hWeJxyb/gSw3VZNUm0FgTQ10a9g5ouOE09jzy0fkyFJDVQOVAJIIGzG02V1hSJNdPEyoDXgFHlveOwvJt+hlLItboBIoTmDmCbvatulir053mZpaQskUQuogH5vrb0SoHTgGX+Pv9MaiqATmfprtl1Fc/EdTQ0iSPwQfLTzq/g11Qxr/V3peKyorASyEZK3e2XHuSBb9U0M8qZmIJS8Lk80OgH7PhtVju80hsKR+oCt0HBDrH5ejhY8JZSMn2FMIY71gq9aQVAI5DpCo3KPi94AoboFK4ACJSlyl9WcDLFAJFCfwL1ersE3InoXWAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 424.46429443359375 -- Current Learning-Rate: 1.0\n",
            "Iteration: 1000 -- Current Loss: 153.51699829101562 -- Current Learning-Rate: 0.9752499999999986\n",
            "Iteration: 2000 -- Current Loss: 145.39328002929688 -- Current Learning-Rate: 0.9504999999999977\n",
            "Iteration: 3000 -- Current Loss: 142.2894287109375 -- Current Learning-Rate: 0.9257499999999951\n",
            "Iteration: 3853 -- Reached Defined Optimum -- Final Loss: 139.99856567382812\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21551B70>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAABxElEQVR4nO3aPWsVQRQG4OeKBAxBbPzAiKQQCw1qYZFKrCyENEIaS/EXWIqFhfgDLKwtRSxs7LXUQiwsNIaUUbQVEZGQ4q6BQMDd2cAx8E5xm2Vmn/tyODs7904maseB4vsHEEAAAQQQQAABBBBAAAHUAw4On3IL1vEMXsEyDrUByhMIoBzQvwhn4AIewQtcg5fwBZfg/WBAeQIBlAP6FeEszsBTPITH+AXz8B1H2gDlCQTQrwau4Dnc1TWi7TELR3G1DVCeQADlgElOywMIIIAAAqgG9H81m4Nzuh3R5R3X/mCT6ffZhM+42GfZ8gQCKAc07IiOweHdr73GcVjExz6rlScQQDmg4aT02/bHjnEW3mAJbugOEv41yhMIYG9ezWZwClZ1Pepn36nlCQRQDmhoRLuMRbyFB/g9aGp5AgHsTSM6gQ04ia+DppYnEEA5YHQjug13cB8WpAj3HWB0I1qANXyC84PnlycQQDlgTBHehHvwxPTHXD8GL1KeQADlgDFPw3dw+u8qw+sP/0ECAbTWwHXdsfkSfGgHlCcQQDmgtQg3dMdSK6QI9zegdUe0atqMrI0ElCcQQDkgf2QKIIAAygFbkycvYHr5KYsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC21551B70>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAADsklEQVR4nO3bO4tkRRQH8N/t7pl2xtfia03EQPNFUHGzhQ1EWNhI2MgFg/UzmIiZialmgomJkSAqqBiI+AnEyBUEX4iBqLvOY6fboOpW3+rbj2lmoTqoA7e5j6pz//fUn1OnzqluBtDoSAMTZ5NmuaJBdntwxhedWSqA4gBGYCpCaVa1PaWkb1pC5HS7yVqXkgogcKDBkPX+Z4Q7K57vxsPhYmWNQDhj8eOLW6ACKA5glM4m8Dj+aK/ugWMCr0YEAv2zWFMDJ7iVrrJn07Z/A/fjgC2wQAXQ3F0EDfYJHDqkM/RJ0qx3kq5KSgVQHMBdJuHmUvr9FUBnMjqVNHge3sEX8DS8KU4tNzcGUNwCFUBxADNH1DA3beUyhCv4AHZwRPyC3/AonFutY05b6l9SKoDiAGaecBV3nsUefIj/4GO8DtfgLfwMr+K9TOOKjMOULbBABbDWESX/cw0ui2R4YGFj94pLs6Ssz4EGnsQvbIEFKoDiAE4/G/Zlo8adlxAyDnfYAgtUAGdZmi3hwILpZ9q7PRAzmsUtUAEUB7AhCRN3Dm3iiPokbJWVt0AFMJcfSFnlvuzCw/iGsBA7hp/gx7bRZdyG6/gyU4vwvWMChyoHKgB0HdG6imuSC3ARn8FT8Du+IxDwB7iEv7JuA3hQXNodq0uzCiDKXFg+0CmyrAq50rMhvIiX4BWhImdfTGKl1hOC402VmkrC7QAQZsOBOJj7lpZmk+TUmLQ/1+FfXIXPW435boOTtv9Je6e4BSqA4gACCSfxcFsntzQlbiI4WKPlGfFT3sbXhJBrQcah79uKW6ACmFuaZWF5k35SkDTU8SHpjhfwCSFkv6rbKCdCX39xC1QAxQHMrQ2nvYvcEeUEhOfgU3wEr/XaJLeWs3FX3cSyLQDW7h84ak8GzI3vffAYYWgvEvcu9WUq5heORDLsqByoAKLMwvIlaYETluWursC78L6wkSWXWWpyap6fqbZX3AIVQHEAoyFz225zyf+SkuQ8bhAryY+IS8oUsi2Ju/qzaXELVAAzRzQmJBHzAU9XOT1eFoOhb+ENi4Z31iNFRH2PVtwCFUBxAM2Y4E0SCc8RNpgsSVSO4Hs8AX8StqSsSrKntGRiY01SbQ+A4IhuiaMy1gnEl8iF9uRXgkdaW2RJqe+aI6oA+tKkv5zsEfDsEYrEN4kF4llzkbeX8BWLJsHUcIeYLe+TtFFrx9sCYJaofAj+1qnvD+m4pTyHvUxd2//A6u1xKXwuboEKoDiA/wE3Z7y783sYzgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 388.31103515625 -- Current Learning-Rate: 1.0\n",
            "Iteration: 1000 -- Current Loss: 270.1741027832031 -- Current Learning-Rate: 0.9752499999999986\n",
            "Iteration: 2000 -- Current Loss: 265.0445556640625 -- Current Learning-Rate: 0.9504999999999977\n",
            "Iteration: 3000 -- Current Loss: 262.56439208984375 -- Current Learning-Rate: 0.9257499999999951\n",
            "Iteration: 4000 -- Current Loss: 261.09521484375 -- Current Learning-Rate: 0.9009999999999914\n",
            "Iteration: 5000 -- Current Loss: 260.2643737792969 -- Current Learning-Rate: 0.8762499999999871\n",
            "Iteration: 6000 -- Current Loss: 259.40966796875 -- Current Learning-Rate: 0.8514999999999817\n",
            "Iteration: 7000 -- Current Loss: 258.56768798828125 -- Current Learning-Rate: 0.8267499999999743\n",
            "Iteration: 8000 -- Current Loss: 257.98834228515625 -- Current Learning-Rate: 0.801999999999967\n",
            "Iteration: 9000 -- Current Loss: 257.6501770019531 -- Current Learning-Rate: 0.7772499999999589\n",
            "Iteration: 10000 -- Current Loss: 257.3182373046875 -- Current Learning-Rate: 0.7524999999999488\n",
            "Iteration: 11000 -- Current Loss: 256.9910583496094 -- Current Learning-Rate: 0.727749999999939\n",
            "Iteration: 12000 -- Current Loss: 256.44512939453125 -- Current Learning-Rate: 0.7029999999999268\n",
            "Iteration: 13000 -- Current Loss: 255.93630981445312 -- Current Learning-Rate: 0.6782499999999132\n",
            "Iteration: 14000 -- Current Loss: 255.50735473632812 -- Current Learning-Rate: 0.6534999999998998\n",
            "Iteration: 15000 -- Current Loss: 255.06301879882812 -- Current Learning-Rate: 0.6287499999998853\n",
            "Iteration: 16000 -- Current Loss: 254.69068908691406 -- Current Learning-Rate: 0.6039999999998691\n",
            "Iteration: 17000 -- Current Loss: 254.17657470703125 -- Current Learning-Rate: 0.5792499999998532\n",
            "Iteration: 18000 -- Current Loss: 253.681396484375 -- Current Learning-Rate: 0.5544999999998367\n",
            "Iteration: 19000 -- Current Loss: 253.380615234375 -- Current Learning-Rate: 0.529749999999819\n",
            "Iteration: 20000 -- Current Loss: 253.11544799804688 -- Current Learning-Rate: 0.5049999999998014\n",
            "Iteration: 21000 -- Current Loss: 252.8699951171875 -- Current Learning-Rate: 0.4802499999998062\n",
            "Iteration: 22000 -- Current Loss: 252.64083862304688 -- Current Learning-Rate: 0.45549999999981644\n",
            "Iteration: 23000 -- Current Loss: 252.4359130859375 -- Current Learning-Rate: 0.4307499999998279\n",
            "Iteration: 24000 -- Current Loss: 252.23013305664062 -- Current Learning-Rate: 0.40599999999983777\n",
            "Iteration: 25000 -- Current Loss: 252.02069091796875 -- Current Learning-Rate: 0.3812499999998472\n",
            "Iteration: 26000 -- Current Loss: 251.8154296875 -- Current Learning-Rate: 0.3564999999998579\n",
            "Iteration: 27000 -- Current Loss: 251.61843872070312 -- Current Learning-Rate: 0.33174999999986815\n",
            "Iteration: 28000 -- Current Loss: 251.42108154296875 -- Current Learning-Rate: 0.30699999999987815\n",
            "Iteration: 29000 -- Current Loss: 251.23782348632812 -- Current Learning-Rate: 0.28224999999988876\n",
            "Iteration: 30000 -- Current Loss: 251.0664825439453 -- Current Learning-Rate: 0.25749999999989676\n"
          ]
        }
      ],
      "source": [
        "def create_cp(iteration_number):\n",
        "  print(\"CREATING CHECKPOINT...\")\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  shutil.make_archive(f\"/content/drive/MyDrive/Colab/data/latent_space_mappings_cp/latent_space_mappings_cp{iteration_number}\", 'zip', \"/content/data/latent_space_mappings\")\n",
        "\n",
        "def save_to_drive(mapped_z, iteration_number, csv_path):\n",
        "  torch.save(mapped_z, f'/content/drive/MyDrive/Colab/data/latent_space_mappings/mapped_z_{iteration_number}.pt')\n",
        "  shutil.copy(csv_path, \"/content/drive/MyDrive/Colab/data/latent_space_mappings/latent_space_mappings.csv\")\n",
        "\n",
        "base_folder = \"/content/data/latent_space_mappings\"\n",
        "csv_path = os.path.join(base_folder, \"latent_space_mappings.csv\")\n",
        "\n",
        "if not os.path.exists(base_folder):\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "if os.path.exists(base_folder):\n",
        "    shutil.rmtree(base_folder)\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "with open(csv_path, 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    fields = [\"filename\", \"label\", \"anomaly\", \"reconstruction_loss\"]\n",
        "    writer.writerow(fields)\n",
        "\n",
        "# Start mapping\n",
        "only_map_anomalies = True\n",
        "t = transforms.ToPILImage()\n",
        "lsm: LatentSpaceMapper = LatentSpaceMapper(generator=generator, discriminator=discriminator, device=device)\n",
        "mapped_images = []\n",
        "cp_counter = 0\n",
        "counter = len(ano_mnist_dataset)\n",
        "for img in ano_mnist_dataset:\n",
        "\n",
        "    # print(f\"{counter} images left\")\n",
        "\n",
        "    if (img[1][\"anomaly\"] == True and only_map_anomalies) or not only_map_anomalies:\n",
        "        mapped_z, reconstruction_loss = lsm.map_image_to_point_in_latent_space(img[0],\n",
        "                                                                               batch_size=1,\n",
        "                                                                               max_opt_iterations=50000,\n",
        "                                                                               opt_threshold=140.0,\n",
        "                                                                               plateu_threshold=0,\n",
        "                                                                               plateu_check_every_n_iter=50000,\n",
        "                                                                               learning_rate=1.0)\n",
        "        mapped_images.append(mapped_z)\n",
        "        with open(csv_path, 'a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            fields = [f'mapped_z_{counter}.pt', img[1][\"label\"], img[1][\"anomaly\"], math.floor(reconstruction_loss)]\n",
        "            writer.writerow(fields)\n",
        "\n",
        "        torch.save(mapped_z, os.path.join(base_folder, f'mapped_z_{counter}.pt'))\n",
        "        save_to_drive(mapped_z, counter, csv_path)\n",
        "        cp_counter += 1\n",
        "        if cp_counter % 50 == 0:\n",
        "          create_cp(counter)\n",
        "          clear_output\n",
        "\n",
        "        print('Original Image')\n",
        "        t(img[0]).resize((128, 128), PIL.Image.NEAREST).show()\n",
        "        original_img = generator(mapped_z).cpu()\n",
        "        img = t(original_img[0]).resize((128, 128), PIL.Image.NEAREST)\n",
        "        print('Mapped and Reconstructed Image')\n",
        "        img.show()\n",
        "        print('-----------------------')\n",
        "\n",
        "    counter-=1\n",
        "\n",
        "create_cp(0)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:17:18.568254955Z",
          "start_time": "2023-06-19T13:17:09.250792045Z"
        },
        "id": "Y611jafizmex",
        "outputId": "9f9ee800-fcb1-450e-ba1a-c0f80dab8e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uEKTkC4VVmif"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}