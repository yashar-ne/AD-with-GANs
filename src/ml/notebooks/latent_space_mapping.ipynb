{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "9rCsmPpNzrBo",
        "outputId": "1a7ac12b-c983-4019-c008-566e14ba94be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:49.352615778Z",
          "start_time": "2023-06-19T13:16:49.272631925Z"
        },
        "id": "uKhESdEpzmea"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import csv\n",
        "import zipfile\n",
        "import PIL\n",
        "import math\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, size_z, num_feature_maps, num_color_channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.size_z = size_z\n",
        "        self.network = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.size_z, num_feature_maps * 4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps * 4, num_feature_maps * 2, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps * 2, num_feature_maps, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(num_feature_maps, num_color_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.network(x)\n",
        "        return output\n",
        "\n",
        "    def gen_shifted(self, x, shift):\n",
        "        shift = torch.unsqueeze(shift, -1)\n",
        "        shift = torch.unsqueeze(shift, -1)\n",
        "        return self.forward(x + shift)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:50.491940517Z",
          "start_time": "2023-06-19T13:16:50.476819472Z"
        },
        "id": "AZKotCEvzmee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_feature_maps, num_color_channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(num_color_channels, num_feature_maps, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps, num_feature_maps * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps * 2, num_feature_maps * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_feature_maps * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(num_feature_maps * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        feature = out\n",
        "        out = self.fc(out)\n",
        "        return out.view(-1, 1).squeeze(1), feature"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:51.402689357Z",
          "start_time": "2023-06-19T13:16:51.383963387Z"
        },
        "id": "9jo7Zrbczmeh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "outputs": [],
      "source": [
        "class LatentSpaceMapper:\n",
        "    def __init__(self, generator: Generator, discriminator: Discriminator, device):\n",
        "        self.generator: Generator = generator\n",
        "        self.generator.to(device)\n",
        "        self.discriminator: Discriminator = discriminator\n",
        "        self.discriminator.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def map_image_to_point_in_latent_space(self, image: torch.Tensor, batch_size=1, size_z=100, max_opt_iterations=50000, opt_threshold=140.0, plateu_threshold=3.0, plateu_check_every_n_iter=4000, learning_rate=0.4):\n",
        "        image.to(self.device)\n",
        "        z = torch.randn(batch_size, size_z, 1, 1, device=self.device, requires_grad=True)\n",
        "        z_optimizer = torch.optim.Adam([z], lr=learning_rate)\n",
        "        losses = []\n",
        "        final_loss = 0\n",
        "        latest_checkpoint_loss = 0\n",
        "\n",
        "        scheduler = lr_scheduler.LinearLR(z_optimizer, start_factor=1.0, end_factor=0.01, total_iters=max_opt_iterations-(math.floor(max_opt_iterations*0.2)))\n",
        "        for i in range(max_opt_iterations):\n",
        "            loss = self.__get_anomaly_score(z, image.unsqueeze(0).to(self.device))\n",
        "            loss.backward()\n",
        "            z_optimizer.step()\n",
        "            final_loss = loss.data.item()\n",
        "\n",
        "            if i == 1:\n",
        "              latest_checkpoint_loss = loss.data.item()\n",
        "\n",
        "            if loss.data.item() < opt_threshold*batch_size:\n",
        "                print(f\"Iteration: {i} -- Reached Defined Optimum -- Final Loss: {loss.data.item()}\")\n",
        "                break\n",
        "\n",
        "            if i % 1000 == 0 or i == max_opt_iterations-1:\n",
        "                print(f\"Iteration: {i} -- Current Loss: {loss.data.item()} -- Current Learning-Rate: {z_optimizer.param_groups[0]['lr']}\")\n",
        "                losses.append(loss.data.item())\n",
        "\n",
        "            if i % plateu_check_every_n_iter == 0:\n",
        "              if abs(loss.data.item()-latest_checkpoint_loss) < plateu_threshold:\n",
        "                print(f\"Reached Plateu at Iteration {i} -- Loss: {loss.data.item()}\")\n",
        "                break\n",
        "              latest_checkpoint_loss = loss.data.item()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "        return z, final_loss\n",
        "\n",
        "    def __get_anomaly_score(self, z, x_query):\n",
        "        lamda = 0.1\n",
        "        g_z = self.generator(z.to(self.device))\n",
        "        #_, x_prop = self.discriminator(x_query)\n",
        "        #_, g_z_prop = self.discriminator(g_z)\n",
        "\n",
        "        loss_r = torch.sum(torch.abs(x_query - g_z))\n",
        "        #loss_d = torch.sum(torch.abs(x_prop - g_z_prop))\n",
        "\n",
        "        # return (1 - lamda) * loss_r + lamda * loss_d\n",
        "        return loss_r"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:52.168904698Z",
          "start_time": "2023-06-19T13:16:52.152945768Z"
        },
        "id": "bDlGQeeozmej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class AnoMNIST(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        root_dir = os.path.join(root_dir, \"AnoMNIST\")\n",
        "        assert os.path.exists(os.path.join(root_dir, \"anomnist_dataset.csv\")), \"Invalid root directory\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.label = pd.read_csv(os.path.join(root_dir, \"anomnist_dataset.csv\"))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.label.iloc[idx, 0])\n",
        "        image_label = {\"label\": self.label.iloc[idx, 1], \"anomaly\": self.label.iloc[idx, 2]}\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, image_label\n",
        "\n",
        "\n",
        "class AnomalyExtendedMNIST(datasets.MNIST):\n",
        "    def __getitem__(self, idx):\n",
        "        return super(AnomalyExtendedMNIST, self).__getitem__(idx)[0], {\"label\": super(AnomalyExtendedMNIST, self).__getitem__(idx)[1], \"anomaly\": False}\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:54.041217345Z",
          "start_time": "2023-06-19T13:16:54.019769104Z"
        },
        "id": "0Nx2n4Iizmel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [],
      "source": [
        "def generate_augmented_mnist_images(base_folder, num, max_augmentation_thickness=5,\n",
        "                                    randomize_augmentation_thickness=False, labels=[]):\n",
        "    assert max_augmentation_thickness <= 7, \"max_augmentation_thickness must be smaller than 7\"\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "\n",
        "    dataset = datasets.MNIST(\n",
        "        root=base_folder,\n",
        "        train=True,\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    if len(labels) > 0:\n",
        "        dataset = [d for d in dataset if (d[1] in labels)]\n",
        "    else:\n",
        "        dataset = dataset.data\n",
        "\n",
        "    ano_mnist_drop_folder = os.path.join(base_folder, \"AnoMNIST\")\n",
        "    csv_path = os.path.join(ano_mnist_drop_folder, \"anomnist_dataset.csv\")\n",
        "\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "    os.makedirs(ano_mnist_drop_folder, exist_ok=True)\n",
        "\n",
        "    augmentation_thickness: int = random.randint(1, max_augmentation_thickness)\n",
        "    for i in range(num):\n",
        "        random_idx = random.randint(0, len(dataset) - 1)\n",
        "        img, label = dataset[random_idx]\n",
        "\n",
        "        augmentation_thickness = random.randint(3,\n",
        "                                                max_augmentation_thickness) if randomize_augmentation_thickness else augmentation_thickness\n",
        "        random_idx = random.randint(4, 20)\n",
        "        for j in range(img.size[0]):\n",
        "            for k in range(augmentation_thickness):\n",
        "                img.putpixel((j, random_idx + k + 1), 0)\n",
        "\n",
        "        img.save(os.path.join(ano_mnist_drop_folder, f\"img_aug_{label}_{i}.png\"))\n",
        "        with open(csv_path, 'a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            fields = [f'img_aug_{label}_{i}.png', f\"{label}\", \"True\"]\n",
        "            writer.writerow(fields)\n",
        "\n",
        "\n",
        "def generate_anomalous_image_files(base_folder, num, labels=[], copy_zip_to=''):\n",
        "    if os.path.exists(base_folder):\n",
        "        shutil.rmtree(base_folder)\n",
        "\n",
        "    ano_mnist_drop_folder = os.path.join(base_folder, \"AnoMNIST\")\n",
        "    csv_path = os.path.join(ano_mnist_drop_folder, \"anomnist_dataset.csv\")\n",
        "\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "    os.makedirs(ano_mnist_drop_folder, exist_ok=True)\n",
        "\n",
        "    with open(csv_path, 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        fields = [\"filename\", \"label\", \"anomaly\"]\n",
        "        writer.writerow(fields)\n",
        "\n",
        "    generate_augmented_mnist_images(base_folder, num=num, labels=labels)\n",
        "    if copy_zip_to:\n",
        "      shutil.make_archive(os.path.join(copy_zip_to, \"AnoMNIST\"), 'zip', ano_mnist_drop_folder)\n",
        "\n",
        "def get_ano_mnist_dataset(transform, root_dir, labels=[9], train_size=0.9):\n",
        "    ano_mnist_dataset = AnoMNIST(\n",
        "        root_dir=root_dir,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    mnist_dataset = AnomalyExtendedMNIST(\n",
        "        root=root_dir,\n",
        "        train=True,\n",
        "        transform=transform,\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    dat = torch.utils.data.ConcatDataset([ano_mnist_dataset, mnist_dataset])\n",
        "\n",
        "    if len(labels) > 0:\n",
        "        dat = [d for d in dat if (d[1]['label'] in labels)]\n",
        "\n",
        "    absolute_train_size = int(len(dat) * train_size)\n",
        "    absolute_test_size = len(dat) - absolute_train_size\n",
        "    return torch.utils.data.random_split(dat, [absolute_train_size, absolute_test_size])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:55.267129710Z",
          "start_time": "2023-06-19T13:16:55.250785327Z"
        },
        "id": "dvoHrYngzmeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ano_mnist_from_drive(drop_folder):\n",
        "  with zipfile.ZipFile('/content/drive/MyDrive/Colab/data/AnoMNIST.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(drop_folder)"
      ],
      "metadata": {
        "id": "CovsspsjqzjN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_color_channels = 1\n",
        "num_feature_maps_g = 64\n",
        "num_feature_maps_d = 64\n",
        "size_z = 100\n",
        "\n",
        "device"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:56.718929255Z",
          "start_time": "2023-06-19T13:16:56.701170727Z"
        },
        "id": "sy0CAfU_zmep",
        "outputId": "7b7b67ef-c317-498c-8600-fa835cc67a6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "generator = Generator(size_z=size_z,\n",
        "                      num_feature_maps=num_feature_maps_g,\n",
        "                      num_color_channels=num_color_channels).to(device)\n",
        "discriminator = Discriminator(num_feature_maps=num_feature_maps_d,\n",
        "                              num_color_channels=num_color_channels).to(device)\n",
        "\n",
        "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab/saved_models/generator.pkl\", map_location=torch.device(device)))\n",
        "discriminator.load_state_dict(torch.load('/content/drive/MyDrive/Colab/saved_models/discriminator.pkl', map_location=torch.device(device)))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:16:58.039609982Z",
          "start_time": "2023-06-19T13:16:57.998343596Z"
        },
        "id": "IJj0sB2Izmeq",
        "outputId": "6209aa4e-51dc-4677-a299-1d0c53a04e44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(.5,), std=(.5,))\n",
        "])\n",
        "\n",
        "# generate_anomalous_image_files(base_folder='/content/data', num=2000, labels=[9]) # number of normals is: 5949\n",
        "load_ano_mnist_from_drive(drop_folder='/content/data')\n",
        "ano_mnist_dataset, _ = get_ano_mnist_dataset(transform=transform, root_dir='/content/data', labels=[9])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:17:07.612568050Z",
          "start_time": "2023-06-19T13:16:59.840564543Z"
        },
        "id": "BRc3Fm41zmes"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0 -- Current Loss: 156.94873046875 -- Current Learning-Rate: 0.5\n",
            "Iteration: 1000 -- Current Loss: 104.63026428222656 -- Current Learning-Rate: 0.4876249999999993\n",
            "Iteration: 2000 -- Current Loss: 95.66035461425781 -- Current Learning-Rate: 0.47524999999999884\n",
            "Iteration: 3000 -- Current Loss: 91.3858642578125 -- Current Learning-Rate: 0.46287499999999754\n",
            "Iteration: 4000 -- Current Loss: 88.63140106201172 -- Current Learning-Rate: 0.4504999999999957\n",
            "Iteration: 5000 -- Current Loss: 87.07815551757812 -- Current Learning-Rate: 0.43812499999999355\n",
            "Iteration: 6000 -- Current Loss: 85.71253967285156 -- Current Learning-Rate: 0.42574999999999086\n",
            "Iteration: 7000 -- Current Loss: 85.07110595703125 -- Current Learning-Rate: 0.41337499999998717\n",
            "Iteration: 8000 -- Current Loss: 83.84423828125 -- Current Learning-Rate: 0.4009999999999835\n",
            "Iteration: 9000 -- Current Loss: 81.56790161132812 -- Current Learning-Rate: 0.38862499999997946\n",
            "Iteration: 10000 -- Current Loss: 78.23014831542969 -- Current Learning-Rate: 0.3762499999999744\n",
            "Iteration: 11000 -- Current Loss: 74.25154113769531 -- Current Learning-Rate: 0.3638749999999695\n",
            "Iteration: 12000 -- Current Loss: 71.89918518066406 -- Current Learning-Rate: 0.3514999999999634\n",
            "Iteration: 13000 -- Current Loss: 69.89797973632812 -- Current Learning-Rate: 0.3391249999999566\n",
            "Iteration: 14000 -- Current Loss: 68.52268981933594 -- Current Learning-Rate: 0.3267499999999499\n",
            "Iteration: 15000 -- Current Loss: 67.5330810546875 -- Current Learning-Rate: 0.3143749999999427\n",
            "Iteration: 16000 -- Current Loss: 66.97129821777344 -- Current Learning-Rate: 0.30199999999993454\n",
            "Iteration: 17000 -- Current Loss: 66.55422973632812 -- Current Learning-Rate: 0.2896249999999266\n",
            "Iteration: 18000 -- Current Loss: 66.24893188476562 -- Current Learning-Rate: 0.27724999999991834\n",
            "Iteration: 19000 -- Current Loss: 65.95684814453125 -- Current Learning-Rate: 0.2648749999999095\n",
            "Iteration: 20000 -- Current Loss: 65.67205810546875 -- Current Learning-Rate: 0.2524999999999007\n",
            "Iteration: 21000 -- Current Loss: 65.3634033203125 -- Current Learning-Rate: 0.2401249999999031\n",
            "Iteration: 22000 -- Current Loss: 65.01258087158203 -- Current Learning-Rate: 0.22774999999990822\n",
            "Iteration: 23000 -- Current Loss: 64.70491027832031 -- Current Learning-Rate: 0.21537499999991394\n",
            "Iteration: 24000 -- Current Loss: 64.38924407958984 -- Current Learning-Rate: 0.20299999999991888\n",
            "Iteration: 25000 -- Current Loss: 64.09870910644531 -- Current Learning-Rate: 0.1906249999999236\n",
            "Iteration: 26000 -- Current Loss: 63.8221435546875 -- Current Learning-Rate: 0.17824999999992894\n",
            "Iteration: 27000 -- Current Loss: 63.563880920410156 -- Current Learning-Rate: 0.16587499999993408\n",
            "Iteration: 28000 -- Current Loss: 63.283477783203125 -- Current Learning-Rate: 0.15349999999993907\n",
            "Iteration: 29000 -- Current Loss: 63.02745819091797 -- Current Learning-Rate: 0.14112499999994438\n",
            "Iteration: 30000 -- Current Loss: 62.81529235839844 -- Current Learning-Rate: 0.12874999999994838\n",
            "Iteration: 31000 -- Current Loss: 62.62205505371094 -- Current Learning-Rate: 0.11637499999995311\n",
            "Iteration: 32000 -- Current Loss: 62.457420349121094 -- Current Learning-Rate: 0.10399999999995808\n",
            "Iteration: 33000 -- Current Loss: 62.31465530395508 -- Current Learning-Rate: 0.09162499999996306\n",
            "Iteration: 34000 -- Current Loss: 62.19050979614258 -- Current Learning-Rate: 0.07924999999996803\n",
            "Iteration: 35000 -- Current Loss: 62.08403015136719 -- Current Learning-Rate: 0.066874999999973\n",
            "Iteration: 36000 -- Current Loss: 61.99427032470703 -- Current Learning-Rate: 0.05449999999997797\n",
            "Iteration: 37000 -- Current Loss: 61.91942596435547 -- Current Learning-Rate: 0.04212499999998294\n",
            "Iteration: 38000 -- Current Loss: 61.85808181762695 -- Current Learning-Rate: 0.02974999999998791\n",
            "Iteration: 39000 -- Current Loss: 61.812870025634766 -- Current Learning-Rate: 0.017374999999992882\n",
            "Iteration: 40000 -- Current Loss: 61.79087829589844 -- Current Learning-Rate: 0.004999999999997896\n",
            "Iteration: 41000 -- Current Loss: 61.78087615966797 -- Current Learning-Rate: 0.004999999999997896\n",
            "Iteration: 42000 -- Current Loss: 61.770729064941406 -- Current Learning-Rate: 0.004999999999997896\n",
            "Iteration: 43000 -- Current Loss: 61.76078796386719 -- Current Learning-Rate: 0.004999999999997896\n",
            "Iteration: 44000 -- Current Loss: 61.751033782958984 -- Current Learning-Rate: 0.004999999999997896\n",
            "Iteration: 45000 -- Current Loss: 61.74126434326172 -- Current Learning-Rate: 0.004999999999997896\n",
            "Reached Plateu at Iteration 45000 -- Loss: 61.74126434326172\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC29C92080>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAABK0lEQVR4nO3aMUoDQRiG4XclYGttYxkLDyB29gExVVpBLDyGnTfwABZ2kiq3SCXiPcROo80G3Eb+kQ1f8/7VLDPDPnwMM8OyXUe29sLvFyBAgAABAgQIECBAgIA8YFIeeQBwD1wDTIFTgFv61hLgshkQT0BAHFBbhIfAHOAK+AJ4HfR/Au8Ax8BbEyCegIA4oCt9pJoDT5WB38B+EyCegIDaRjTbNjb0O84DsAA4Ggx8bgbEExAQB9SvZAA80l/JAD4A7gb9Z82AeAICGtfAzeiAeAIC4oDajWiHFU9AgAABAgQIECBAgAABAuKAxu8Df9Qa4GT7tAIuKtPiCQgQIECAAAHjnYYv8Os0LFc8AQFxwHiL8Px/0+IJCBAgQIAAAQIE+P+AAAEC4oAf3T4V+/Atc+4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC29C90A30>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAD50lEQVR4nO3bPYssRRQG4Kd7ZpeV1XWvYqJGBpr5FYmpoYImmvgDFPwJRoKKIhf8A4LofzAxMBLE8IpipBdUruLHvavudb27M2NQ1TVdMz0fglgT1AvTdPVUVb9Uv5w6fc7pptVHi5l4aLqTcJZa3ZVRNuw8G9ZdNc2GLaNd/df/g0qgOIFxOmu75qS7ktQ4b426jkfd2Btwq9+x7TpO6Ss5QxJx8RWoBJrE4Ah+71pJGzPC01xjTAbQxp+LFfftdyyKSqA4gSC2va7ZdJemuAQ3CTvdBUNKzHfLhDY7mekZspE4W5t1LIVKoMkZpD1ihf1YxgoN6CaaDP6FqoFKIGKcN5PFWIOGQHyf4AzZw9/d+Iawt16C71kr6eIrUAk0WzNo4X18DJdxJ9H1/RaPEYXQ4ZC4mQ17xfNpS6ISKE5gOxGOcBdBbftwRRTZAwRv/nH4Ls0r+llHBEN0Sgwi6CZhB1agEihOYKMI9+BZvEuwe28SRPQJvAFP4T7C3vgXi9GCVi9QMFn+vyQqgfGKS8m1OYSncQy/4gPCg27gB4J9+RruFVVzq5ttmg7DKL4ClUBxAgMizH3oU/gcT8KLopNFNCZvwf14FD7DE/+KQPEVqAQGNJAjBSpHhD1ongiBE3gJX8CDoiHK/PMVSO94RVEJFCewUYQXhJf8r+Bui1vbCTyC2wm6uoMhEWYZv/lJ8RWoBLZ7NbtNjAZcFjakBdyDLwlu03Pw0RazHrMDK1AJFCew0RCBM3wIrwmKDO9fCc+IZuUMP2577xN2YAUqgeIEto+U/veoKZvdINCMsmarZ2jyjNua/FyOPDS+aUTxFagEihMY55KZiP71n9nlrJppQFbZ5eXSuxWohmg3CCx4RK34+Bv9Z7imPiA9yHfgBdFZehh/bLj3NI0viUqgOIEBt/ycRREOY5IOR2L+7hjX4RW8bfUkjRof2BUC43RsCBmPX+jFePKtZYU0TvFb17gGn25x77oZVQJgPKJXUXldzJHs6SX77YuJuJFeRmVetT3Dq/A8rhJCm6mGEkNldXvswApUAsUJjCf0Qk7pJAlwRrCU5ywoKTeJrxOKWB6Cn7JOw9XAF+zAClQC2wUqT8XSowuL9QEJ1+Ab/SI7FhMlyx9KFV+BSqA4gYFAZcoNz2WTOiUHbbI05CohtnCTUN/0Hr2P8PLxI9Ut3xUC4wOCWWkJZZMNoUYyFWvPzcqhXg3JHK1Y1fayWNV2Q/+LzGP8LM49JWho3A0tikqgOIEQLc8MxbqwwIGQmls5XfwtFBk0YhD+TO9DzLob7gaB7bNmaetY8+nSurG5NA5EQ1d8BSqB4gT+AWQbxvrskOswAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 162.2948455810547 -- Current Learning-Rate: 0.5\n",
            "Iteration: 1000 -- Current Loss: 114.2788314819336 -- Current Learning-Rate: 0.4876249999999993\n",
            "Iteration: 2000 -- Current Loss: 100.65801239013672 -- Current Learning-Rate: 0.47524999999999884\n",
            "Iteration: 3000 -- Current Loss: 86.15257263183594 -- Current Learning-Rate: 0.46287499999999754\n",
            "Iteration: 4000 -- Current Loss: 79.00949096679688 -- Current Learning-Rate: 0.4504999999999957\n",
            "Iteration: 5000 -- Current Loss: 74.72309875488281 -- Current Learning-Rate: 0.43812499999999355\n",
            "Iteration: 6000 -- Current Loss: 72.35913848876953 -- Current Learning-Rate: 0.42574999999999086\n",
            "Iteration: 7000 -- Current Loss: 69.68896484375 -- Current Learning-Rate: 0.41337499999998717\n",
            "Iteration: 8000 -- Current Loss: 68.00210571289062 -- Current Learning-Rate: 0.4009999999999835\n",
            "Iteration: 9000 -- Current Loss: 66.69047546386719 -- Current Learning-Rate: 0.38862499999997946\n",
            "Iteration: 10000 -- Current Loss: 65.83134460449219 -- Current Learning-Rate: 0.3762499999999744\n",
            "Iteration: 11000 -- Current Loss: 65.1434326171875 -- Current Learning-Rate: 0.3638749999999695\n",
            "Iteration: 12000 -- Current Loss: 64.88788604736328 -- Current Learning-Rate: 0.3514999999999634\n",
            "Iteration: 13000 -- Current Loss: 64.69436645507812 -- Current Learning-Rate: 0.3391249999999566\n",
            "Iteration: 14000 -- Current Loss: 64.54129028320312 -- Current Learning-Rate: 0.3267499999999499\n",
            "Iteration: 15000 -- Current Loss: 64.41055297851562 -- Current Learning-Rate: 0.3143749999999427\n",
            "Iteration: 16000 -- Current Loss: 64.24113464355469 -- Current Learning-Rate: 0.30199999999993454\n",
            "Iteration: 17000 -- Current Loss: 64.08268737792969 -- Current Learning-Rate: 0.2896249999999266\n",
            "Iteration: 18000 -- Current Loss: 63.937034606933594 -- Current Learning-Rate: 0.27724999999991834\n",
            "Iteration: 19000 -- Current Loss: 63.79499435424805 -- Current Learning-Rate: 0.2648749999999095\n",
            "Iteration: 20000 -- Current Loss: 63.64170837402344 -- Current Learning-Rate: 0.2524999999999007\n",
            "Iteration: 21000 -- Current Loss: 63.50212860107422 -- Current Learning-Rate: 0.2401249999999031\n",
            "Iteration: 22000 -- Current Loss: 63.37648391723633 -- Current Learning-Rate: 0.22774999999990822\n",
            "Iteration: 23000 -- Current Loss: 63.275577545166016 -- Current Learning-Rate: 0.21537499999991394\n",
            "Iteration: 24000 -- Current Loss: 63.17566680908203 -- Current Learning-Rate: 0.20299999999991888\n",
            "Iteration: 25000 -- Current Loss: 63.0798454284668 -- Current Learning-Rate: 0.1906249999999236\n",
            "Iteration: 26000 -- Current Loss: 62.99701690673828 -- Current Learning-Rate: 0.17824999999992894\n",
            "Iteration: 27000 -- Current Loss: 62.9000358581543 -- Current Learning-Rate: 0.16587499999993408\n",
            "Iteration: 28000 -- Current Loss: 62.78071212768555 -- Current Learning-Rate: 0.15349999999993907\n",
            "Iteration: 29000 -- Current Loss: 62.66438293457031 -- Current Learning-Rate: 0.14112499999994438\n",
            "Iteration: 30000 -- Current Loss: 62.58464431762695 -- Current Learning-Rate: 0.12874999999994838\n",
            "Iteration: 31000 -- Current Loss: 62.51695251464844 -- Current Learning-Rate: 0.11637499999995311\n",
            "Iteration: 32000 -- Current Loss: 62.456756591796875 -- Current Learning-Rate: 0.10399999999995808\n",
            "Iteration: 33000 -- Current Loss: 62.40970993041992 -- Current Learning-Rate: 0.09162499999996306\n",
            "Iteration: 34000 -- Current Loss: 62.375640869140625 -- Current Learning-Rate: 0.07924999999996803\n",
            "Iteration: 35000 -- Current Loss: 62.344581604003906 -- Current Learning-Rate: 0.066874999999973\n",
            "Iteration: 36000 -- Current Loss: 62.31525802612305 -- Current Learning-Rate: 0.05449999999997797\n",
            "Iteration: 37000 -- Current Loss: 62.29457092285156 -- Current Learning-Rate: 0.04212499999998294\n",
            "Iteration: 38000 -- Current Loss: 62.27762222290039 -- Current Learning-Rate: 0.02974999999998791\n",
            "Iteration: 39000 -- Current Loss: 62.26655578613281 -- Current Learning-Rate: 0.017374999999992882\n",
            "Iteration: 40000 -- Current Loss: 62.261512756347656 -- Current Learning-Rate: 0.004999999999997896\n",
            "Reached Plateu at Iteration 40000 -- Loss: 62.261512756347656\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC29C91390>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAABmElEQVR4nO3aoUucYRwH8M/JEAbLS2MMy8ZmujCwjIVhW7EMZM1gWdofsGBaMdmNFotpjIHdIGiazSALy0MMY4jh3hNB5O6eV/gtfJ90vHfP7z58+fHcc8/7DgZqx1zx9wcQQAABBBBAAAEEEEAAAQQQQAAe3EuVt9iC5+MrX3EA3yZMLU8ggHLAIIdUAQQQQAABVAMm7og+wUcM4fLW+3N3X/4F7+D07vrlCQRQDpjYhEuMGvCa+he+YA0+wDI2YH78oXO8gEcT6pcnEEB2xQEEEEAAAQQw/UHlEBZuXvkBf2AX7+FQt5E/nrZseQIBlAPuZ0t2hFfc2JZPPcoTCKD3HZOncIKH8BI/Z5pfnkAA5YDeC9FjONP13nDm+eUJBNB7IVoev3jTNr88gQDKAX2acBW24bvuRPJ85iLlCQRQDujThBfXBbbxu61IeQIBtPbAIj7DP0b3TvbaCpUnEEA5oLUJ1/Gabje+2Q4oTyCA1r9mK9iBZzT/EPEfJBBAOaB1IXqiezRln+6Qsm2UJxBAnh8IoBxwBRD8Je3PzzkeAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC29C906D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAD7ElEQVR4nO3bv6tjRRQH8M9Nbt5bs/tc0RVE0UpRsRFECy3tbO1U7FTQ0spGsLZRKy20EAsFVxsLQfAPWLEURBQRZHUL9emum33PvMRi5g735t7kxQWZV8wXEiZ3fuSbM4dzzpwzqcYwwRwWIqqmsew8qeNg894MTT84aqamharOwDRtJDMKgewE6gns4RpcFXVnaZDcCDfBr1r6iahkp0TdnDePl71Gf8WsKATqCs7gsHlU0SLWNTSHuNhfpcKUoEw1/GztrneRXQKFQHYC1QjGVh1hMkRH/zOB7BIoBEIIkza6EhTCGAfHzB0wNFX/Ua8/TRult5woBLITCIaooxtDowb7r0MJR/FlbtXt5kIhUO8RzNEZ1gYyw/pRdVpjQkR0I8GIXUqD9nAOZtinZfqyS6AQyE6gvkI48p/jeIvUwRRehT/wNHyIe+AC3tGsNsMvBPuzJPzwRdPIikIgO4HgDae4BX4XcgTba2IfE0Ki4HK/b4ybCebwiBMggUIghOXXcD98JW7/1f+0ylLLN84Z3P8GlynesBBooUoHtKREC9Yaoh2tbNYARqJebxrUm5EVhUCVGKSD0i7BUBzSil/+Et9uhYfxNkEr3I234DshGPID/ul8U01wVLPO4+wSKASyE6i6DMaiNs57I5+Ep0QluoRH4FN4CC/Co+Ih8xPR46W0Z9V86ubfs0ugEKi7Hzekpj8jGJnH4eNm7n7TvwP3iaarG/Hsiltfi+W5hZIjKgQiqh1a1f5tsKai9yy8iffg5eFpe6Jb7abMc6IQyE6gPqJV9j8lnu/3rSpZwsDjCg8SorDXh6ctGXKy2SVQCNS7cJvozQ5EJ5fO92sUoYspnoEv8BurpZNlfPm7NzW7BAqB7ASqmiFNS2nzFFZvwhP4CE6LSrwQf9xxSpxdAoVAvWaPjruDllARqiFzeBcvNF0LYjVvONovYXkhgF5+oHuJdxuchq/xDTwvesPjkFKj2SVQCKzkB/pbv8GjjOAVQiHsMUINdyuky3LZJVAIZCdQbc2gHxrdAefhA7xPPPs3o8u13kJgK9QjwuWnGRtvcXZVaoSX4C74UzxNdixpV237f5tJC2VFIRD+XzAWcgQuWq22rcEID8CPhLRA3+wMRDyTZv2UMcgugUIgO4E6lVTOEvjcAN9q/eNpAG+IQdhrBEO0BinJsGgaU0JdutymOxkEqglho3bgTtwLX4qeaU0h74JwayAMut2qsoxFZbpCCP5TVlzTmHECJFAIZCdQJyU7gO/xE0OF/oQKPsdzxNu8y17/kah/aBVKZr1GdgkUAisXmZY2p6eTRZmK+zic576OQnAuFALZCfwL1//QHS4bgQ8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 141.27664184570312 -- Current Learning-Rate: 0.5\n",
            "Iteration: 1000 -- Current Loss: 77.81382751464844 -- Current Learning-Rate: 0.4876249999999993\n",
            "Iteration: 2000 -- Current Loss: 76.80068969726562 -- Current Learning-Rate: 0.47524999999999884\n",
            "Iteration: 3000 -- Current Loss: 76.31684875488281 -- Current Learning-Rate: 0.46287499999999754\n",
            "Iteration: 4000 -- Current Loss: 76.13809204101562 -- Current Learning-Rate: 0.4504999999999957\n",
            "Iteration: 5000 -- Current Loss: 76.01832580566406 -- Current Learning-Rate: 0.43812499999999355\n",
            "Iteration: 6000 -- Current Loss: 75.91580200195312 -- Current Learning-Rate: 0.42574999999999086\n",
            "Iteration: 7000 -- Current Loss: 75.84980773925781 -- Current Learning-Rate: 0.41337499999998717\n",
            "Iteration: 8000 -- Current Loss: 75.733642578125 -- Current Learning-Rate: 0.4009999999999835\n",
            "Iteration: 9000 -- Current Loss: 75.64558410644531 -- Current Learning-Rate: 0.38862499999997946\n",
            "Iteration: 10000 -- Current Loss: 75.59909057617188 -- Current Learning-Rate: 0.3762499999999744\n",
            "Iteration: 11000 -- Current Loss: 75.56956481933594 -- Current Learning-Rate: 0.3638749999999695\n",
            "Iteration: 12000 -- Current Loss: 75.54081726074219 -- Current Learning-Rate: 0.3514999999999634\n",
            "Iteration: 13000 -- Current Loss: 75.53216552734375 -- Current Learning-Rate: 0.3391249999999566\n",
            "Iteration: 14000 -- Current Loss: 75.51542663574219 -- Current Learning-Rate: 0.3267499999999499\n",
            "Iteration: 15000 -- Current Loss: 75.50498962402344 -- Current Learning-Rate: 0.3143749999999427\n",
            "Reached Plateu at Iteration 15000 -- Loss: 75.50498962402344\n",
            "Original Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC29C92D40>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAABvklEQVR4nO3ZP2tTURgH4CfFpSJ1E1pUShHxIzj6FdwUN0HRoZOLFBFnEZcO7oKLbkLFyUlcVHAQQQURJ3UQnCwiwSE5xYI09yaBV+F3pnvPn+TJj5d7wrmDgdq2UPz9AQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQRQD9jXeeYmnMM2XMLDne7Lf058ASe7fmx5AgEMOr26PYFncABf4Egb2g+vsApPcQsedQWUJxBAOaDbg+gzlhhV4vnWexgOwUrrWtSj/vAPJBBAOWBiER6FJ+3uOz7BFl7CBgzb+L3egPIEApi4Gx6H18bUq8b737U2fgZuGz+MtnC6F6A8gQDKAd2K8I0xdeeJcwM/4Sas4R0cw8degPIEApi4GX2AB7gA73GH0X/v7V0Th6Zq5QkEUA6YWIS/4Gy7W/77pFPTA8oTCKD7GdFebaldXMF6r6XlCQRQDphPEV5sF297Ly1PIIBywHyKcMHUP6U8gQDmUwNDfIOvvZeWJxBAOWDmIrzO6DTzLtzvvb48gQC6vbbbo60yOh/6AQd7ry9PIIBywMxFuAnP8Zjshv8lYOYamLWVJxBAOeA3nJ8yC2+MZ8gAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped and Reconstructed Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FAC29C92D70>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAADtUlEQVR4nO3bO4hkRRTG8d+93eP6Wl/4YAIfiKKImGkgKBioCIaiLIJgZigGBoKJiImJpgYGpoupICKCgokgGgkuyBoI7uJ71XGd7W6DenTfx+70tMPWBHWgm9u3uqr/nP6oc+pU3abVtym0mMO5QfskvZ2DRX5bx5rUf57GH/7+RbYKUBxgOrw1lF3XWoKamnxrbREuBuMX90AFaPZP0MCl4kQygb83ByjugQpQHGBkItrLGgL4zkEAFPdABdhAA9fA7uD2gtX4tIa1+a2kVYDiABtEwxHLGVEzuOg2bWGWPk04BB6oAAejgT1/JV208WWhLs0qQLQNoiFCWn4vfEmUE9yK3+GMOOMgSC4LcZ76n+UQeKACFAfYQIS3wFf4B+4iSO5O+AJfw6NWRUgMi1PcDP/iNIfAAxUgaKCxZp2nwSNwBA/AX6npHsLc8hrhP+7aFjyE7+ASsVhU3AMVoDhAEOFQgOeR5f14nbA2/Dl3bUSR/YjH4ONB1y3C3HS6M35xD1SAXjDKPPP+F90A7+OVdLFDTHSuxzOEQPXt+C+18Hkaerdzu6RVgOIAPRFeLSYyf3RuN3iVEMS+YaU+3sKTeIKQJH3a6ZpXgn+OAxT3QAVYaqAhpLfDOchEmGx8LwQcjbC88hJclUY6gZOdrnslWsU9UAGKA0wnhCT7dsJscRZOibKcwXV4GN7AD6nvNjwNV6Ruz+uvyHJJfFhfX7aXtApQHGA6I6zSPoMP8HJqW06JraitiRARHcXlcBMcF6Phg/op2ULsUkV4WAGaCb2QtcXKP5Y3Ot4jpD4nCcuyu+EFgiLehA/xXOp6GTFkntE/OpJLl8U9UAGKA4xs2TSMZVLb8KwgREfFhf5T8Ha6yNXyta24ByrA/962a+AT3EGIaMeG7RfIzYt7oAIUB9h0265r7woZu3cGTVl/U8ZOaxb3QAXYVAM5o1nAi/iFkPp0Le/YDldsR9JFUasAxQF6RSr2sX+3tFP4lbAs68a/hrG610JM/Yt7oAIUB+iJ8DaxCDWzOnflR17oi7SFj8T6eoNr4TexfrCbRluIg+TnE+re8eEAWKblLaHiuMPKv5btSsKOSDer2SacZroPfkoDzdJF3jGZMHasoLgHKkBxgOVENCekVDnQTVg5hJtPq7Tp2w3cSDhufhweX+0xz8PmgYZW3AMVYCQtz/PPfHir82FB3MPdxVsE2cwHPS50UKq4BypAcYCDKVIdEw5TOrHv/sU9UAEuzvMFnLdiWdwDFaA4wH/67LUzcTB+ZwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "Iteration: 0 -- Current Loss: 166.10537719726562 -- Current Learning-Rate: 0.5\n",
            "Iteration: 1000 -- Current Loss: 73.893310546875 -- Current Learning-Rate: 0.4876249999999993\n",
            "Iteration: 2000 -- Current Loss: 71.39752197265625 -- Current Learning-Rate: 0.47524999999999884\n",
            "Iteration: 3000 -- Current Loss: 69.92355346679688 -- Current Learning-Rate: 0.46287499999999754\n"
          ]
        }
      ],
      "source": [
        "def create_cp(iteration_number):\n",
        "  print(\"CREATING CHECKPOINT...\")\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  shutil.make_archive(f\"/content/drive/MyDrive/Colab/data/latent_space_mappings_cp/latent_space_mappings_cp{iteration_number}\", 'zip', \"/content/data/latent_space_mappings\")\n",
        "\n",
        "def save_to_drive(mapped_z, iteration_number, csv_path):\n",
        "  torch.save(mapped_z, f'/content/drive/MyDrive/Colab/data/latent_space_mappings/mapped_z_{iteration_number}.pt')\n",
        "  shutil.copy(csv_path, \"/content/drive/MyDrive/Colab/data/latent_space_mappings/latent_space_mappings.csv\")\n",
        "\n",
        "base_folder = \"/content/data/latent_space_mappings\"\n",
        "csv_path = os.path.join(base_folder, \"latent_space_mappings.csv\")\n",
        "\n",
        "if not os.path.exists(base_folder):\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "if os.path.exists(base_folder):\n",
        "    shutil.rmtree(base_folder)\n",
        "    os.mkdir(base_folder)\n",
        "\n",
        "with open(csv_path, 'a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    fields = [\"filename\", \"label\", \"anomaly\", \"reconstruction_loss\"]\n",
        "    writer.writerow(fields)\n",
        "\n",
        "# Start mapping\n",
        "only_map_anomalies = True\n",
        "t = transforms.ToPILImage()\n",
        "lsm: LatentSpaceMapper = LatentSpaceMapper(generator=generator, discriminator=discriminator, device=device)\n",
        "mapped_images = []\n",
        "cp_counter = 0\n",
        "counter = len(ano_mnist_dataset)\n",
        "for img in ano_mnist_dataset:\n",
        "\n",
        "    # print(f\"{counter} images left\")\n",
        "\n",
        "    if (img[1][\"anomaly\"] == True and only_map_anomalies) or not only_map_anomalies:\n",
        "        mapped_z, reconstruction_loss = lsm.map_image_to_point_in_latent_space(img[0],\n",
        "                                                                               batch_size=1,\n",
        "                                                                               max_opt_iterations=50000,\n",
        "                                                                               opt_threshold=50.0,\n",
        "                                                                               plateu_threshold=0.1,\n",
        "                                                                               plateu_check_every_n_iter=5000,\n",
        "                                                                               learning_rate=0.5)\n",
        "        mapped_images.append(mapped_z)\n",
        "        with open(csv_path, 'a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            fields = [f'mapped_z_{counter}.pt', img[1][\"label\"], img[1][\"anomaly\"], math.floor(reconstruction_loss)]\n",
        "            writer.writerow(fields)\n",
        "\n",
        "        torch.save(mapped_z, os.path.join(base_folder, f'mapped_z_{counter}.pt'))\n",
        "        save_to_drive(mapped_z, counter, csv_path)\n",
        "        cp_counter += 1\n",
        "        if cp_counter % 50 == 0:\n",
        "          create_cp(counter)\n",
        "          clear_output\n",
        "\n",
        "        print('Original Image')\n",
        "        t(img[0]).resize((128, 128), PIL.Image.NEAREST).show()\n",
        "        original_img = generator(mapped_z).cpu()\n",
        "        img = t(original_img[0]).resize((128, 128), PIL.Image.NEAREST)\n",
        "        print('Mapped and Reconstructed Image')\n",
        "        img.show()\n",
        "        print('-----------------------')\n",
        "\n",
        "    counter-=1\n",
        "\n",
        "create_cp(0)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-19T13:17:18.568254955Z",
          "start_time": "2023-06-19T13:17:09.250792045Z"
        },
        "id": "Y611jafizmex",
        "outputId": "910a76a8-acc6-4435-bfd1-446b51d0af87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uEKTkC4VVmif"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}