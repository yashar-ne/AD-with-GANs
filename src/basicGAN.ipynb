{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly following\n",
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html<br>\n",
    "https://github.com/AKASHKADEL/dcgan-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.discriminator import Discriminator\n",
    "from models.generator import Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if GPU is available. If so activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform image data to tensor and normalize.<br>\n",
    "Normalization: output = (input - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(.5,), std=(.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST Training-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set various hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "learning_rate = 0.002\n",
    "num_epochs = 2\n",
    "num_color_channels = 1\n",
    "num_feature_maps_g = 32\n",
    "num_feature_maps_d = 32\n",
    "size_z = 100\n",
    "adam_beta1 = 0.2\n",
    "num_gpu = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into dataloader, create generator, discriminator objects and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(size_z=size_z,\n",
    "                      num_feature_maps=num_feature_maps_g,\n",
    "                      num_color_channels=num_color_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(num_feature_maps=num_feature_maps_d,\n",
    "                              num_color_channels=num_color_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate fixed noise for final image generation. Create Adam optimizer objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(64, size_z, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerG = optim.Adam(generator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_images, _) in enumerate(dataloader):\n",
    "        # get batch-size from actual image batch\n",
    "        bs = real_images.shape[0]\n",
    "\n",
    "        # -- train discriminator --\n",
    "\n",
    "        # reset/clear discriminators gradient\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        # move images to either CPU or GPU\n",
    "        real_images = real_images.to(device)\n",
    "\n",
    "        # creates a label tensor filled with 1s\n",
    "        label = torch.full((bs,), real_label, device=device)\n",
    "\n",
    "        # get probs for discriminators guess on the real images\n",
    "        output = discriminator(real_images)\n",
    "\n",
    "        # get loss for real images. that means it calculates the difference\n",
    "        # between the output of the model with the current parameter and the\n",
    "        # target (goal) of what the model is supposed to do\n",
    "        # output --> current outcome of the model\n",
    "        # label  --> target of the model\n",
    "        lossD_real = criterion(output, label)\n",
    "\n",
    "        # calculates the gradient (using chain-rule)\n",
    "        # see https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
    "        lossD_real.backward()\n",
    "\n",
    "        # Gets the mean value of all results from the discriminator to get an average\n",
    "        # probability of all sample evaluations (for real data ) --> D(x)\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # create noise as an input for the G in order to create fake images\n",
    "        noise = torch.randn(bs, size_z, 1, 1, device=device)\n",
    "\n",
    "        # use generator to map input noise to an output that is supposed do become fake images during training\n",
    "        fake_images = generator(noise)\n",
    "\n",
    "        # creates a label tensor filled with 0s\n",
    "        label.fill_(fake_label)\n",
    "\n",
    "        # get discriminators guess on fake images\n",
    "        output = discriminator(fake_images.detach())\n",
    "\n",
    "        # get loss for fake images\n",
    "        lossD_fake = criterion(output, label)\n",
    "\n",
    "        # adjust parameter to identify fakes\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        # gets the mean value of all results from the discriminator to get an average\n",
    "        # probability of all sample evaluations. this time for the fake images that were\n",
    "        # generated by the generator --> D(G(z))\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        # calculate loss\n",
    "        lossD = lossD_real + lossD_fake\n",
    "\n",
    "        # adjust models (discriminator) parameter\n",
    "        optimizerD.step()\n",
    "\n",
    "        # -- train generator --\n",
    "\n",
    "        # reset/clear generators gradient\n",
    "        generator.zero_grad()\n",
    "\n",
    "        # creates a label tensor filled with 1s\n",
    "        label.fill_(real_label)\n",
    "\n",
    "        # get discriminators guess on fake images\n",
    "        output = discriminator(fake_images)\n",
    "\n",
    "        # get loss for fake images\n",
    "        lossG = criterion(output, label)\n",
    "\n",
    "        # adjust parameter to generate fakes\n",
    "        lossG.backward()\n",
    "\n",
    "        # gets the mean value of all results from the discriminator to get an average\n",
    "        # probability of all sample evaluations. this time for the fake images that were\n",
    "        # generated by the generator --> D(G(z))\n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        # adjust models (generator) parameter\n",
    "        optimizerG.step()\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     lossD.item(), lossG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(lossG.item())\n",
    "        D_losses.append(lossD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(dataloader) - 1)):\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot losses of both, generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.plot(D_losses, label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['animation.embed_limit'] = 100\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
