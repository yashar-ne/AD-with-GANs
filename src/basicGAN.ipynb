{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\nMostly following<br>\n",
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html<br>\n",
    "tps://github.com/AKASHKADEL/dcgan-mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.discriminator import Discriminator\n",
    "from models.generator import Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if GPU is available. If so activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(.5,), std=(.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST Training-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set various hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "learning_rate = 0.002\n",
    "num_epochs = 2\n",
    "num_color_channels = 1\n",
    "num_feature_maps_g = 32\n",
    "num_feature_maps_d = 32\n",
    "size_z = 100\n",
    "adam_beta1 = 0.2\n",
    "num_gpu = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into dataloader, create generator, discriminator objects and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(size_z=size_z,\n",
    "                      num_feature_maps=num_feature_maps_g,\n",
    "                      num_color_channels=num_color_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(num_feature_maps=num_feature_maps_d,\n",
    "                              num_color_channels=num_color_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate fixed noise for final image generation. Create Adam optimizer objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(64, size_z, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerG = optim.Adam(generator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(adam_beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/2][0/469]\tLoss_D: 1.4029\tLoss_G: 2.3853\tD(x): 0.5091\tD(G(z)): 0.5063 / 0.1006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 80\u001B[0m\n\u001B[1;32m     77\u001B[0m lossG \u001B[38;5;241m=\u001B[39m criterion(output, label)\n\u001B[1;32m     79\u001B[0m \u001B[38;5;66;03m# adjust parameter to generate fakes\u001B[39;00m\n\u001B[0;32m---> 80\u001B[0m \u001B[43mlossG\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;66;03m# gets the mean value of all results from the discriminator to get an average\u001B[39;00m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;66;03m# probability of all sample evaluations. this time for the fake images that were\u001B[39;00m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;66;03m# generated by the generator --> D(G(z))\u001B[39;00m\n\u001B[1;32m     85\u001B[0m D_G_z2 \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/.conda/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/thesis/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_images, _) in enumerate(dataloader):\n",
    "        # get batch-size from actual image batch\n",
    "        bs = real_images.shape[0]\n\n",
    "        # -- train discriminator --\n\n",
    "        # reset/clear discriminators gradient\n",
    "        discriminator.zero_grad()\n\n",
    "        # move images to either CPU or GPU\n",
    "        real_images = real_images.to(device)\n\n",
    "        # creates a label tensor filled with 1s\n",
    "        label = torch.full((bs,), real_label, device=device)\n\n",
    "        # get probs for discriminators guess on the real images\n",
    "        output = discriminator(real_images)\n\n",
    "        # get loss for real images. that means it calculates the difference\n",
    "        # between the output of the model with the current parameter and the\n",
    "        # target (goal) of what the model is supposed to do\n",
    "        # output --> current outcome of the model\n",
    "        # label  --> target of the model\n",
    "        lossD_real = criterion(output, label)\n\n",
    "        # calculates the gradient (using chain-rule)\n",
    "        # see https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
    "        lossD_real.backward()\n\n",
    "        # Gets the mean value of all results from the discriminator to get an average\n",
    "        # probability of all sample evaluations (for real data ) --> D(x)\n",
    "        D_x = output.mean().item()\n\n",
    "        # create noise as an input for the G in order to create fake images\n",
    "        noise = torch.randn(bs, size_z, 1, 1, device=device)\n\n",
    "        # use generator to map input noise to an output that is supposed do become fake images during training\n",
    "        fake_images = generator(noise)\n\n",
    "        # creates a label tensor filled with 0s\n",
    "        label.fill_(fake_label)\n\n",
    "        # get discriminators guess on fake images\n",
    "        output = discriminator(fake_images.detach())\n\n",
    "        # get loss for fake images\n",
    "        lossD_fake = criterion(output, label)\n\n",
    "        # adjust parameter to identify fakes\n",
    "        lossD_fake.backward()\n\n",
    "        # gets the mean value of all results from the discriminator to get an average\n",
    "        # probability of all sample evaluations. this time for the fake images that were\n",
    "        # generated by the generator --> D(G(z))\n",
    "        D_G_z1 = output.mean().item()\n\n",
    "        # calculate loss\n",
    "        lossD = lossD_real + lossD_fake\n\n",
    "        # adjust models (discriminator) parameter\n",
    "        optimizerD.step()\n\n",
    "        # -- train generator --\n\n",
    "        # reset/clear generators gradient\n",
    "        generator.zero_grad()\n\n",
    "        # creates a label tensor filled with 1s\n",
    "        label.fill_(real_label)\n\n",
    "        # get discriminators guess on fake images\n",
    "        output = discriminator(fake_images)\n\n",
    "        # get loss for fake images\n",
    "        lossG = criterion(output, label)\n\n",
    "        # adjust parameter to generate fakes\n",
    "        lossG.backward()\n\n",
    "        # gets the mean value of all results from the discriminator to get an average\n",
    "        # probability of all sample evaluations. this time for the fake images that were\n",
    "        # generated by the generator --> D(G(z))\n",
    "        D_G_z2 = output.mean().item()\n\n",
    "        # adjust models (generator) parameter\n",
    "        optimizerG.step()\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     lossD.item(), lossG.item(), D_x, D_G_z1, D_G_z2))\n\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(lossG.item())\n",
    "        D_losses.append(lossD.item())\n\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(dataloader) - 1)):\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot losses of both, generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.plot(D_losses, label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['animation.embed_limit'] = 100\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
