- [Paper](https://proceedings.mlr.press/v119/voynov20a.html)
- Main Idea is to identify direction in latent space that of a pretrained GAN, if moved along them, will change the generated image in a human interpretable way
	- e.g. blur or background-removal
- method works unsupervised
- "In a nutshell, the approach seeks a set of directions corresponding to diverse image transformations, i.e., it is easy to distinguish one transformation from another"
- model-agnostic
	- can also be used for DCGAN
- Method jointly learns a set of directions together with model that distinguishes the corresponding image transformations
	- directions do not interfere and hence only affect a single factor of variation
- The model consist of
	- A pretrained GAN that maps a latent space coordinate to a corresponding Image
		- $G:z\longrightarrow I$, with $z \in \mathbb{R}^{d}$ and $d$ as the dimension (number of elements in latent space vector)
	- A Matrix $A$, with $A \in \mathbb{R}^{d \times K}$ and $K$ as the number of direction the system will discover. $K$ is a hyperparameter
	- A Reconstructor $R$, that obtains an image-pair of the form $(G(z), G(z+A(\varepsilon e_{k})))$,
		- where $z$ is a random variable, drawn from the normal distributed image space -> $z \sim \mathcal{N}(0,I)$
		- and the second image is a transformation of the first one that was generated by a shifted variable
			- $z+A(\varepsilon e_{k})$, with $e_{k}$ being an axes-aligned unit-vector (0,0,0,0,0,...,$1_{k}$,0,0,0,0,...,0) and $\varepsilon$ a scalar
				- shifts $\varepsilon$ units towards the $k^{th}$ axes
		- In the end the Reconstructor learns, for two given images to predict the direction and the magnitude of the shift
			- $R(I_{1}, I_{2}) = (\hat{k}, \hat{\varepsilon})$, where $\hat{k}$ is the prediction of the direction index $k \in \{1,...K\}$
	- 
